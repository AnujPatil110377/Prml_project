{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing ANN Implementation"]},{"cell_type":"markdown","metadata":{},"source":["Importing Dataset and Combining "]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-19T01:37:34.343690Z","iopub.status.busy":"2024-04-19T01:37:34.343230Z","iopub.status.idle":"2024-04-19T01:37:34.947398Z","shell.execute_reply":"2024-04-19T01:37:34.945434Z","shell.execute_reply.started":"2024-04-19T01:37:34.343658Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["       textID                                               text  \\\n","0  cb774db0d1                I`d have responded, if I were going   \n","1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2  088c60f138                          my boss is bullying me...   \n","3  9642c003ef                     what interview! leave me alone   \n","4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","\n","                         selected_text sentiment Time of Tweet Age of User  \\\n","0  I`d have responded, if I were going   neutral       morning        0-20   \n","1                             Sooo SAD  negative          noon       21-30   \n","2                          bullying me  negative         night       31-45   \n","3                       leave me alone  negative       morning       46-60   \n","4                        Sons of ****,  negative          noon       60-70   \n","\n","       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n","0  Afghanistan        38928346.0         652860.0             60.0  \n","1      Albania         2877797.0          27400.0            105.0  \n","2      Algeria        43851044.0        2381740.0             18.0  \n","3      Andorra           77265.0            470.0            164.0  \n","4       Angola        32866272.0        1246700.0             26.0  \n"]}],"source":["import pandas as pd\n","\n","df1 = pd.read_csv('train.csv',encoding='latin1')\n","df2 = pd.read_csv('test.csv',encoding='latin1')\n","\n","# Merge the DataFrames\n","train_data = pd.concat([df1, df2], ignore_index=True)\n","\n","# Write the merged DataFrame to a new CSV file\n","train_data.to_csv('merged_file.csv', index=False)\n","print(train_data.head())\n"]},{"cell_type":"markdown","metadata":{},"source":["Removing the Unnecessary columns"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:39.371712Z","iopub.status.busy":"2024-04-19T01:37:39.370463Z","iopub.status.idle":"2024-04-19T01:37:39.382078Z","shell.execute_reply":"2024-04-19T01:37:39.380404Z","shell.execute_reply.started":"2024-04-19T01:37:39.371677Z"},"trusted":true},"outputs":[],"source":["columns_to_remove = ['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n","train_data.drop(columns=columns_to_remove, inplace=True)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:42.065849Z","iopub.status.busy":"2024-04-19T01:37:42.065069Z","iopub.status.idle":"2024-04-19T01:37:42.080171Z","shell.execute_reply":"2024-04-19T01:37:42.079026Z","shell.execute_reply.started":"2024-04-19T01:37:42.065803Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32291</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32292</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32293</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32294</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32295</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32296 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                    I`d have responded, if I were going   neutral\n","1          Sooo SAD I will miss you here in San Diego!!!  negative\n","2                              my boss is bullying me...  negative\n","3                         what interview! leave me alone  negative\n","4       Sons of ****, why couldn`t they put them on t...  negative\n","...                                                  ...       ...\n","32291                                                NaN       NaN\n","32292                                                NaN       NaN\n","32293                                                NaN       NaN\n","32294                                                NaN       NaN\n","32295                                                NaN       NaN\n","\n","[32296 rows x 2 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:45.393561Z","iopub.status.busy":"2024-04-19T01:37:45.393032Z","iopub.status.idle":"2024-04-19T01:37:45.434840Z","shell.execute_reply":"2024-04-19T01:37:45.433152Z","shell.execute_reply.started":"2024-04-19T01:37:45.393509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing Values:\n"," text         1282\n","sentiment    1281\n","dtype: int64\n","\n","Duplicate Rows: 1280\n"]}],"source":["# Check for missing values\n","missing_values = train_data.isnull().sum()\n","print(\"Missing Values:\\n\", missing_values)\n","\n","# Check for duplicates\n","duplicate_rows = train_data.duplicated().sum()\n","print(\"\\nDuplicate Rows:\", duplicate_rows)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:48.121570Z","iopub.status.busy":"2024-04-19T01:37:48.121153Z","iopub.status.idle":"2024-04-19T01:37:48.137707Z","shell.execute_reply":"2024-04-19T01:37:48.135593Z","shell.execute_reply.started":"2024-04-19T01:37:48.121540Z"},"trusted":true},"outputs":[],"source":["train_data.dropna(subset=['text'], inplace=True)\n","# train_data.dropna(subset=['text_lower'],inplace=True)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:50.965382Z","iopub.status.busy":"2024-04-19T01:37:50.964966Z","iopub.status.idle":"2024-04-19T01:37:50.983116Z","shell.execute_reply":"2024-04-19T01:37:50.981600Z","shell.execute_reply.started":"2024-04-19T01:37:50.965355Z"},"trusted":true},"outputs":[],"source":["# Lowercase Conversion\n","train_data['text'] = train_data['text'].str.lower()\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:01.703114Z","iopub.status.busy":"2024-04-19T01:38:01.702690Z","iopub.status.idle":"2024-04-19T01:38:01.718499Z","shell.execute_reply":"2024-04-19T01:38:01.717036Z","shell.execute_reply.started":"2024-04-19T01:38:01.703084Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>i`d have responded, if i were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego!!!</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>all alone in this old house again.  thanks for...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>i know what you mean. my little dog is sinkin...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                    i`d have responded, if i were going   neutral\n","1          sooo sad i will miss you here in san diego!!!  negative\n","2                              my boss is bullying me...  negative\n","3                         what interview! leave me alone  negative\n","4       sons of ****, why couldn`t they put them on t...  negative\n","...                                                  ...       ...\n","31010  its at 3 am, im very tired but i can`t sleep  ...  negative\n","31011  all alone in this old house again.  thanks for...  positive\n","31012   i know what you mean. my little dog is sinkin...  negative\n","31013  _sutra what is your next youtube video gonna b...  positive\n","31014   http://twitpic.com/4woj2 - omgssh  ang cute n...  positive\n","\n","[31014 rows x 2 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["*****Text cleaning***"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:08.468825Z","iopub.status.busy":"2024-04-19T01:38:08.468377Z","iopub.status.idle":"2024-04-19T01:38:08.794800Z","shell.execute_reply":"2024-04-19T01:38:08.793373Z","shell.execute_reply.started":"2024-04-19T01:38:08.468796Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of  why couldnt they put them on the rel...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am im very tired but i cant sleep  bu...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>all alone in this old house again  thanks for ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>i know what you mean my little dog is sinking...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>sutra what is your next youtube video gonna be...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>omgssh  ang cute ng bby</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                      id have responded if i were going   neutral\n","1             sooo sad i will miss you here in san diego  negative\n","2                                 my boss is bullying me  negative\n","3                          what interview leave me alone  negative\n","4       sons of  why couldnt they put them on the rel...  negative\n","...                                                  ...       ...\n","31010  its at 3 am im very tired but i cant sleep  bu...  negative\n","31011  all alone in this old house again  thanks for ...  positive\n","31012   i know what you mean my little dog is sinking...  negative\n","31013  sutra what is your next youtube video gonna be...  positive\n","31014                            omgssh  ang cute ng bby  positive\n","\n","[31014 rows x 2 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","\n","def clean_text(text):\n","    if isinstance(text, str):  # Check if text is a string\n","        # Remove special characters, HTML tags, and links\n","        cleaned_text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n","        cleaned_text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", cleaned_text)  # Remove links\n","        cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # Remove special characters\n","        return cleaned_text.lower()  # Convert text to lowercase\n","    else:\n","        return text  # Return unchanged if not a string\n","\n","# Apply text cleaning to 'text' column\n","train_data['text'] = train_data['text'].apply(clean_text)\n","train_data"]},{"cell_type":"markdown","metadata":{},"source":["**Stopwords Removal: Remove common stopwords while preserving the links.**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:22.060730Z","iopub.status.busy":"2024-04-19T01:38:22.060261Z","iopub.status.idle":"2024-04-19T01:38:27.306346Z","shell.execute_reply":"2024-04-19T01:38:27.304969Z","shell.execute_reply.started":"2024-04-19T01:38:22.060699Z"},"trusted":true},"outputs":[],"source":["import requests\n","\n","# Download the stopwords file\n","url = \"https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\"\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Extract stopwords from the content\n","    stopwords = response.text.split(\",\")\n","else:\n","    print(\"Failed to download stopwords file.\")\n","\n","# Stopwords removal function\n","def remove_stopwords(text):\n","    if isinstance(text, str):\n","        # Split the text into tokens using whitespace as delimiter\n","        tokens = text.split()\n","        # Remove stopwords from the tokens\n","        filtered_tokens = [word for word in tokens if word.lower() not in stopwords]\n","        # Join the filtered tokens back into a string\n","        filtered_text = ' '.join(filtered_tokens)\n","        return filtered_text\n","    else:\n","        return text\n","\n","\n","\n","\n","\n","# Applying the stopwords removal function to the 'text' column in the train_data DataFrame\n","train_data['text'] = train_data['text'].apply(remove_stopwords)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:33.731014Z","iopub.status.busy":"2024-04-19T01:38:33.730511Z","iopub.status.idle":"2024-04-19T01:38:33.753932Z","shell.execute_reply":"2024-04-19T01:38:33.753033Z","shell.execute_reply.started":"2024-04-19T01:38:33.730981Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>text_lower</th>\n","      <th>tokens</th>\n","      <th>text_without_stopwords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","      <td>i`d have responded, if i were going</td>\n","      <td>[id, have, responded, if, i, were, going]</td>\n","      <td>responded</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>negative</td>\n","      <td>sooo sad i will miss you here in san diego!!!</td>\n","      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n","      <td>sooo sad san diego</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me</td>\n","      <td>negative</td>\n","      <td>my boss is bullying me...</td>\n","      <td>[my, boss, is, bullying, me]</td>\n","      <td>boss bullying</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview leave me alone</td>\n","      <td>negative</td>\n","      <td>what interview! leave me alone</td>\n","      <td>[what, interview, leave, me, alone]</td>\n","      <td>interview leave</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of  why couldnt they put them on the rel...</td>\n","      <td>negative</td>\n","      <td>sons of ****, why couldn`t they put them on t...</td>\n","      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n","      <td>sons releases bought</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am im very tired but i cant sleep  bu...</td>\n","      <td>negative</td>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","      <td>[its, at, 3, am, im, very, tired, but, i, cant...</td>\n","      <td>3 tired sleep</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>all alone in this old house again  thanks for ...</td>\n","      <td>positive</td>\n","      <td>all alone in this old house again.  thanks for...</td>\n","      <td>[all, alone, in, this, old, house, again, than...</td>\n","      <td>house net alive kicking invented net wanna kis...</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>i know what you mean my little dog is sinking...</td>\n","      <td>negative</td>\n","      <td>i know what you mean. my little dog is sinkin...</td>\n","      <td>[i, know, what, you, mean, my, little, dog, is...</td>\n","      <td>dog sinking depression someplace tropical</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>sutra what is your next youtube video gonna be...</td>\n","      <td>positive</td>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","      <td>[sutra, what, is, your, next, youtube, video, ...</td>\n","      <td>sutra youtube video gonna love videos</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>omgssh  ang cute ng bby</td>\n","      <td>positive</td>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","      <td>[omgssh, ang, cute, ng, bby]</td>\n","      <td>omgssh ang cute bby</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment  \\\n","0                      id have responded if i were going   neutral   \n","1             sooo sad i will miss you here in san diego  negative   \n","2                                 my boss is bullying me  negative   \n","3                          what interview leave me alone  negative   \n","4       sons of  why couldnt they put them on the rel...  negative   \n","...                                                  ...       ...   \n","31010  its at 3 am im very tired but i cant sleep  bu...  negative   \n","31011  all alone in this old house again  thanks for ...  positive   \n","31012   i know what you mean my little dog is sinking...  negative   \n","31013  sutra what is your next youtube video gonna be...  positive   \n","31014                            omgssh  ang cute ng bby  positive   \n","\n","                                              text_lower  \\\n","0                    i`d have responded, if i were going   \n","1          sooo sad i will miss you here in san diego!!!   \n","2                              my boss is bullying me...   \n","3                         what interview! leave me alone   \n","4       sons of ****, why couldn`t they put them on t...   \n","...                                                  ...   \n","31010  its at 3 am, im very tired but i can`t sleep  ...   \n","31011  all alone in this old house again.  thanks for...   \n","31012   i know what you mean. my little dog is sinkin...   \n","31013  _sutra what is your next youtube video gonna b...   \n","31014   http://twitpic.com/4woj2 - omgssh  ang cute n...   \n","\n","                                                  tokens  \\\n","0              [id, have, responded, if, i, were, going]   \n","1      [sooo, sad, i, will, miss, you, here, in, san,...   \n","2                           [my, boss, is, bullying, me]   \n","3                    [what, interview, leave, me, alone]   \n","4      [sons, of, why, couldnt, they, put, them, on, ...   \n","...                                                  ...   \n","31010  [its, at, 3, am, im, very, tired, but, i, cant...   \n","31011  [all, alone, in, this, old, house, again, than...   \n","31012  [i, know, what, you, mean, my, little, dog, is...   \n","31013  [sutra, what, is, your, next, youtube, video, ...   \n","31014                       [omgssh, ang, cute, ng, bby]   \n","\n","                                  text_without_stopwords  \n","0                                              responded  \n","1                                     sooo sad san diego  \n","2                                          boss bullying  \n","3                                        interview leave  \n","4                                   sons releases bought  \n","...                                                  ...  \n","31010                                      3 tired sleep  \n","31011  house net alive kicking invented net wanna kis...  \n","31012          dog sinking depression someplace tropical  \n","31013              sutra youtube video gonna love videos  \n","31014                                omgssh ang cute bby  \n","\n","[31014 rows x 5 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:48:34.702502Z","iopub.status.busy":"2024-04-19T01:48:34.700655Z","iopub.status.idle":"2024-04-19T01:48:34.722585Z","shell.execute_reply":"2024-04-19T01:48:34.721428Z","shell.execute_reply.started":"2024-04-19T01:48:34.702432Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Encode the sentiment labels\n","label_encoder = LabelEncoder()\n","train_data['sentiment'] = label_encoder.fit_transform(train_data['sentiment'])\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["class CustomTokenizer:\n","    def __init__(self, num_words=None):\n","        self.num_words = num_words\n","        self.word_to_index = {}\n","        self.index_to_word = {}\n","        self.word_counts = {}\n","        self.index = 1  # Start index from 1 (0 reserved for padding)\n","\n","    def fit_on_texts(self, texts):\n","        for text in texts:\n","            for word in text.split():\n","                if word not in self.word_counts:\n","                    self.word_counts[word] = 1\n","                else:\n","                    self.word_counts[word] += 1\n","\n","        # Sort words by frequency and select top num_words if specified\n","        sorted_words = sorted(self.word_counts.items(), key=lambda x: x[1], reverse=True)\n","        if self.num_words:\n","            sorted_words = sorted_words[:self.num_words]\n","\n","        # Assign index to each word\n","        for word, _ in sorted_words:\n","            self.word_to_index[word] = self.index\n","            self.index_to_word[self.index] = word\n","            self.index += 1\n","\n","    def texts_to_sequences(self, texts):\n","        sequences = []\n","        for text in texts:\n","            sequence = [self.word_to_index[word] for word in text.split() if word in self.word_to_index]\n","            sequences.append(sequence)\n","        return sequences\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Final Python Script with all the implementations"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model with optimizer: adam, epochs: 2, batch_size: 64\n","Epoch 1/2\n","272/272 [==============================] - 6s 18ms/step - loss: 0.9030 - accuracy: 0.5666 - val_loss: 0.7436 - val_accuracy: 0.6851\n","Epoch 2/2\n","272/272 [==============================] - 3s 10ms/step - loss: 0.6270 - accuracy: 0.7507 - val_loss: 0.7542 - val_accuracy: 0.6890\n","Validation Accuracy: 0.6843462586402893\n","Training model with optimizer: adam, epochs: 2, batch_size: 128\n","Epoch 1/2\n","136/136 [==============================] - 3s 14ms/step - loss: 1.0760 - accuracy: 0.4173 - val_loss: 1.0206 - val_accuracy: 0.4718\n","Epoch 2/2\n","136/136 [==============================] - 1s 10ms/step - loss: 0.8616 - accuracy: 0.5935 - val_loss: 0.7881 - val_accuracy: 0.6632\n","Validation Accuracy: 0.6637111306190491\n","Training model with optimizer: adam, epochs: 2, batch_size: 256\n","Epoch 1/2\n","68/68 [==============================] - 2s 26ms/step - loss: 1.0652 - accuracy: 0.4156 - val_loss: 0.9717 - val_accuracy: 0.5266\n","Epoch 2/2\n","68/68 [==============================] - 1s 16ms/step - loss: 0.8059 - accuracy: 0.6652 - val_loss: 0.7577 - val_accuracy: 0.6879\n","Validation Accuracy: 0.6827341318130493\n","Training model with optimizer: adam, epochs: 3, batch_size: 64\n","Epoch 1/3\n","272/272 [==============================] - 4s 11ms/step - loss: 0.9514 - accuracy: 0.5449 - val_loss: 0.7611 - val_accuracy: 0.6783\n","Epoch 2/3\n","272/272 [==============================] - 3s 11ms/step - loss: 0.6363 - accuracy: 0.7456 - val_loss: 0.7458 - val_accuracy: 0.6932\n","Epoch 3/3\n","272/272 [==============================] - 3s 11ms/step - loss: 0.4496 - accuracy: 0.8372 - val_loss: 0.8415 - val_accuracy: 0.6494\n","Validation Accuracy: 0.644688069820404\n","Training model with optimizer: adam, epochs: 3, batch_size: 128\n","Epoch 1/3\n","136/136 [==============================] - 2s 13ms/step - loss: 0.9806 - accuracy: 0.5133 - val_loss: 0.7858 - val_accuracy: 0.6689\n","Epoch 2/3\n","136/136 [==============================] - 2s 12ms/step - loss: 0.6689 - accuracy: 0.7274 - val_loss: 0.7376 - val_accuracy: 0.6922\n","Epoch 3/3\n","136/136 [==============================] - 1s 10ms/step - loss: 0.5185 - accuracy: 0.8065 - val_loss: 0.7792 - val_accuracy: 0.6826\n","Validation Accuracy: 0.6748347282409668\n","Training model with optimizer: adam, epochs: 3, batch_size: 256\n","Epoch 1/3\n","68/68 [==============================] - 2s 19ms/step - loss: 1.0385 - accuracy: 0.4566 - val_loss: 0.9060 - val_accuracy: 0.5918\n","Epoch 2/3\n","68/68 [==============================] - 1s 14ms/step - loss: 0.7572 - accuracy: 0.6823 - val_loss: 0.7463 - val_accuracy: 0.6816\n","Epoch 3/3\n","68/68 [==============================] - 1s 14ms/step - loss: 0.5896 - accuracy: 0.7711 - val_loss: 0.7531 - val_accuracy: 0.6871\n","Validation Accuracy: 0.6814444661140442\n","Training model with optimizer: adam, epochs: 5, batch_size: 64\n","Epoch 1/5\n","272/272 [==============================] - 5s 14ms/step - loss: 0.9095 - accuracy: 0.5687 - val_loss: 0.7445 - val_accuracy: 0.6832\n","Epoch 2/5\n","272/272 [==============================] - 3s 11ms/step - loss: 0.6202 - accuracy: 0.7533 - val_loss: 0.7556 - val_accuracy: 0.6909\n","Epoch 3/5\n","272/272 [==============================] - 3s 10ms/step - loss: 0.4374 - accuracy: 0.8430 - val_loss: 0.8649 - val_accuracy: 0.6580\n","Epoch 4/5\n","272/272 [==============================] - 3s 11ms/step - loss: 0.2738 - accuracy: 0.9106 - val_loss: 1.0254 - val_accuracy: 0.6432\n","Epoch 5/5\n","272/272 [==============================] - 3s 10ms/step - loss: 0.1761 - accuracy: 0.9448 - val_loss: 1.2657 - val_accuracy: 0.6397\n","Validation Accuracy: 0.6384007930755615\n","Training model with optimizer: adam, epochs: 5, batch_size: 128\n","Epoch 1/5\n","136/136 [==============================] - 2s 13ms/step - loss: 0.9932 - accuracy: 0.4986 - val_loss: 0.7950 - val_accuracy: 0.6595\n","Epoch 2/5\n","136/136 [==============================] - 1s 11ms/step - loss: 0.6740 - accuracy: 0.7269 - val_loss: 0.7476 - val_accuracy: 0.6866\n","Epoch 3/5\n","136/136 [==============================] - 1s 10ms/step - loss: 0.5204 - accuracy: 0.8035 - val_loss: 0.7862 - val_accuracy: 0.6840\n","Epoch 4/5\n","136/136 [==============================] - 2s 11ms/step - loss: 0.3845 - accuracy: 0.8679 - val_loss: 0.9048 - val_accuracy: 0.6581\n","Epoch 5/5\n","136/136 [==============================] - 2s 11ms/step - loss: 0.2635 - accuracy: 0.9185 - val_loss: 1.0151 - val_accuracy: 0.6444\n","Validation Accuracy: 0.6451717019081116\n","Training model with optimizer: adam, epochs: 5, batch_size: 256\n","Epoch 1/5\n","68/68 [==============================] - 2s 19ms/step - loss: 1.0732 - accuracy: 0.4331 - val_loss: 1.0241 - val_accuracy: 0.5090\n","Epoch 2/5\n","68/68 [==============================] - 1s 14ms/step - loss: 0.9268 - accuracy: 0.5566 - val_loss: 0.8652 - val_accuracy: 0.6036\n","Epoch 3/5\n","68/68 [==============================] - 1s 14ms/step - loss: 0.7246 - accuracy: 0.7047 - val_loss: 0.7648 - val_accuracy: 0.6740\n","Epoch 4/5\n","68/68 [==============================] - 1s 15ms/step - loss: 0.5774 - accuracy: 0.7794 - val_loss: 0.7602 - val_accuracy: 0.6818\n","Epoch 5/5\n","68/68 [==============================] - 1s 14ms/step - loss: 0.4756 - accuracy: 0.8269 - val_loss: 0.8048 - val_accuracy: 0.6734\n","Validation Accuracy: 0.6701595783233643\n","Training model with optimizer: adam, epochs: 8, batch_size: 64\n","Epoch 1/8\n","272/272 [==============================] - 4s 11ms/step - loss: 0.9726 - accuracy: 0.5115 - val_loss: 0.7765 - val_accuracy: 0.6771\n","Epoch 2/8\n","272/272 [==============================] - 3s 10ms/step - loss: 0.6861 - accuracy: 0.7252 - val_loss: 0.7461 - val_accuracy: 0.6875\n","Epoch 3/8\n","272/272 [==============================] - 3s 10ms/step - loss: 0.5452 - accuracy: 0.7905 - val_loss: 0.7720 - val_accuracy: 0.6918\n","Epoch 4/8\n","272/272 [==============================] - 3s 10ms/step - loss: 0.4250 - accuracy: 0.8477 - val_loss: 0.8527 - val_accuracy: 0.6733\n","Epoch 5/8\n","272/272 [==============================] - 3s 10ms/step - loss: 0.3105 - accuracy: 0.8968 - val_loss: 0.9688 - val_accuracy: 0.6592\n","Epoch 6/8\n","272/272 [==============================] - 3s 10ms/step - loss: 0.2237 - accuracy: 0.9330 - val_loss: 1.1184 - val_accuracy: 0.6515\n","Epoch 7/8\n","272/272 [==============================] - 3s 10ms/step - loss: 0.1654 - accuracy: 0.9505 - val_loss: 1.2744 - val_accuracy: 0.6397\n","Epoch 8/8\n","272/272 [==============================] - 3s 11ms/step - loss: 0.1294 - accuracy: 0.9599 - val_loss: 1.3709 - val_accuracy: 0.6357\n","Validation Accuracy: 0.6393680572509766\n","Training model with optimizer: adam, epochs: 8, batch_size: 128\n","Epoch 1/8\n","136/136 [==============================] - 2s 14ms/step - loss: 1.0130 - accuracy: 0.4917 - val_loss: 0.8265 - val_accuracy: 0.6443\n","Epoch 2/8\n","136/136 [==============================] - 2s 11ms/step - loss: 0.6849 - accuracy: 0.7239 - val_loss: 0.7384 - val_accuracy: 0.6893\n","Epoch 3/8\n","136/136 [==============================] - 2s 12ms/step - loss: 0.5195 - accuracy: 0.8092 - val_loss: 0.7914 - val_accuracy: 0.6752\n","Epoch 4/8\n","136/136 [==============================] - 2s 11ms/step - loss: 0.3885 - accuracy: 0.8654 - val_loss: 0.8694 - val_accuracy: 0.6533\n","Epoch 5/8\n","136/136 [==============================] - 2s 11ms/step - loss: 0.2744 - accuracy: 0.9151 - val_loss: 1.0054 - val_accuracy: 0.6459\n","Epoch 6/8\n","136/136 [==============================] - 2s 11ms/step - loss: 0.1958 - accuracy: 0.9421 - val_loss: 1.1317 - val_accuracy: 0.6306\n","Epoch 7/8\n","136/136 [==============================] - 1s 11ms/step - loss: 0.1464 - accuracy: 0.9569 - val_loss: 1.2761 - val_accuracy: 0.6244\n","Epoch 8/8\n","136/136 [==============================] - 2s 12ms/step - loss: 0.1169 - accuracy: 0.9654 - val_loss: 1.3445 - val_accuracy: 0.6145\n","Validation Accuracy: 0.6195389032363892\n","Training model with optimizer: adam, epochs: 8, batch_size: 256\n","Epoch 1/8\n","68/68 [==============================] - 2s 18ms/step - loss: 1.0517 - accuracy: 0.4478 - val_loss: 0.9411 - val_accuracy: 0.5736\n","Epoch 2/8\n","68/68 [==============================] - 1s 16ms/step - loss: 0.7746 - accuracy: 0.6791 - val_loss: 0.7465 - val_accuracy: 0.6776\n","Epoch 3/8\n","68/68 [==============================] - 1s 15ms/step - loss: 0.5818 - accuracy: 0.7763 - val_loss: 0.7541 - val_accuracy: 0.6854\n","Epoch 4/8\n","68/68 [==============================] - 1s 15ms/step - loss: 0.4630 - accuracy: 0.8335 - val_loss: 0.7968 - val_accuracy: 0.6795\n","Epoch 5/8\n","68/68 [==============================] - 1s 15ms/step - loss: 0.3548 - accuracy: 0.8849 - val_loss: 0.8894 - val_accuracy: 0.6623\n","Epoch 6/8\n","68/68 [==============================] - 1s 15ms/step - loss: 0.2669 - accuracy: 0.9200 - val_loss: 0.9810 - val_accuracy: 0.6497\n","Epoch 7/8\n","68/68 [==============================] - 1s 16ms/step - loss: 0.2013 - accuracy: 0.9421 - val_loss: 1.1049 - val_accuracy: 0.6397\n","Epoch 8/8\n","68/68 [==============================] - 1s 15ms/step - loss: 0.1561 - accuracy: 0.9567 - val_loss: 1.1923 - val_accuracy: 0.6318\n","Validation Accuracy: 0.6316298842430115\n","Training model with optimizer: rmsprop, epochs: 2, batch_size: 64\n","Epoch 1/2\n","272/272 [==============================] - 4s 13ms/step - loss: 0.9403 - accuracy: 0.5457 - val_loss: 0.7717 - val_accuracy: 0.6758\n","Epoch 2/2\n","272/272 [==============================] - 3s 10ms/step - loss: 0.6941 - accuracy: 0.7148 - val_loss: 0.7338 - val_accuracy: 0.6987\n","Validation Accuracy: 0.6940190196037292\n","Training model with optimizer: rmsprop, epochs: 2, batch_size: 128\n","Epoch 1/2\n","136/136 [==============================] - 3s 14ms/step - loss: 1.0352 - accuracy: 0.4668 - val_loss: 0.9076 - val_accuracy: 0.6276\n","Epoch 2/2\n","136/136 [==============================] - 1s 10ms/step - loss: 0.7725 - accuracy: 0.6725 - val_loss: 0.7653 - val_accuracy: 0.6670\n","Validation Accuracy: 0.6585522890090942\n","Training model with optimizer: rmsprop, epochs: 2, batch_size: 256\n","Epoch 1/2\n","68/68 [==============================] - 2s 19ms/step - loss: 1.0583 - accuracy: 0.4418 - val_loss: 0.9539 - val_accuracy: 0.5177\n","Epoch 2/2\n","68/68 [==============================] - 1s 14ms/step - loss: 0.8362 - accuracy: 0.6390 - val_loss: 0.7967 - val_accuracy: 0.6337\n","Validation Accuracy: 0.6293728947639465\n","Training model with optimizer: rmsprop, epochs: 3, batch_size: 64\n","Epoch 1/3\n","272/272 [==============================] - 4s 12ms/step - loss: 0.9192 - accuracy: 0.5623 - val_loss: 0.7666 - val_accuracy: 0.6777\n","Epoch 2/3\n","272/272 [==============================] - 3s 10ms/step - loss: 0.6784 - accuracy: 0.7244 - val_loss: 0.7480 - val_accuracy: 0.6928\n","Epoch 3/3\n","272/272 [==============================] - 3s 11ms/step - loss: 0.5763 - accuracy: 0.7767 - val_loss: 0.7457 - val_accuracy: 0.6922\n","Validation Accuracy: 0.6862808465957642\n","Training model with optimizer: rmsprop, epochs: 3, batch_size: 128\n","Epoch 1/3\n","136/136 [==============================] - 3s 14ms/step - loss: 0.9711 - accuracy: 0.5187 - val_loss: 0.8146 - val_accuracy: 0.6486\n","Epoch 2/3\n","136/136 [==============================] - 1s 10ms/step - loss: 0.7049 - accuracy: 0.7117 - val_loss: 0.7323 - val_accuracy: 0.6897\n","Epoch 3/3\n","136/136 [==============================] - 1s 11ms/step - loss: 0.6046 - accuracy: 0.7628 - val_loss: 0.7405 - val_accuracy: 0.6948\n","Validation Accuracy: 0.6891826391220093\n","Training model with optimizer: rmsprop, epochs: 3, batch_size: 256\n","Epoch 1/3\n","68/68 [==============================] - 2s 19ms/step - loss: 1.0259 - accuracy: 0.4772 - val_loss: 0.8911 - val_accuracy: 0.5954\n","Epoch 2/3\n","68/68 [==============================] - 1s 13ms/step - loss: 0.7709 - accuracy: 0.6757 - val_loss: 0.7597 - val_accuracy: 0.6810\n","Epoch 3/3\n","68/68 [==============================] - 1s 13ms/step - loss: 0.6438 - accuracy: 0.7423 - val_loss: 0.7419 - val_accuracy: 0.6885\n","Validation Accuracy: 0.6825729608535767\n","Training model with optimizer: rmsprop, epochs: 5, batch_size: 64\n","Epoch 1/5\n","272/272 [==============================] - 4s 10ms/step - loss: 0.9826 - accuracy: 0.5084 - val_loss: 0.8051 - val_accuracy: 0.6449\n","Epoch 2/5\n","272/272 [==============================] - 3s 10ms/step - loss: 0.7144 - accuracy: 0.7055 - val_loss: 0.7516 - val_accuracy: 0.6820\n","Epoch 3/5\n","272/272 [==============================] - 3s 10ms/step - loss: 0.6089 - accuracy: 0.7612 - val_loss: 0.7721 - val_accuracy: 0.6874\n","Epoch 4/5\n","272/272 [==============================] - 3s 10ms/step - loss: 0.5212 - accuracy: 0.8040 - val_loss: 0.7880 - val_accuracy: 0.6889\n","Epoch 5/5\n","272/272 [==============================] - 2s 9ms/step - loss: 0.4267 - accuracy: 0.8473 - val_loss: 0.8552 - val_accuracy: 0.6608\n","Validation Accuracy: 0.6591971516609192\n","Training model with optimizer: rmsprop, epochs: 5, batch_size: 128\n","Epoch 1/5\n","136/136 [==============================] - 2s 14ms/step - loss: 0.9834 - accuracy: 0.5118 - val_loss: 0.8141 - val_accuracy: 0.6561\n","Epoch 2/5\n","136/136 [==============================] - 1s 11ms/step - loss: 0.7260 - accuracy: 0.7027 - val_loss: 0.7389 - val_accuracy: 0.6963\n","Epoch 3/5\n","136/136 [==============================] - 1s 10ms/step - loss: 0.6327 - accuracy: 0.7513 - val_loss: 0.7332 - val_accuracy: 0.7004\n","Epoch 4/5\n","136/136 [==============================] - 1s 11ms/step - loss: 0.5594 - accuracy: 0.7883 - val_loss: 0.7545 - val_accuracy: 0.6949\n","Epoch 5/5\n","136/136 [==============================] - 1s 10ms/step - loss: 0.4873 - accuracy: 0.8178 - val_loss: 0.7904 - val_accuracy: 0.6873\n","Validation Accuracy: 0.6807996034622192\n","Training model with optimizer: rmsprop, epochs: 5, batch_size: 256\n","Epoch 1/5\n","68/68 [==============================] - 2s 19ms/step - loss: 1.0721 - accuracy: 0.4467 - val_loss: 0.9849 - val_accuracy: 0.5114\n","Epoch 2/5\n","68/68 [==============================] - 1s 13ms/step - loss: 0.8535 - accuracy: 0.6418 - val_loss: 0.8003 - val_accuracy: 0.6503\n","Epoch 3/5\n","68/68 [==============================] - 1s 14ms/step - loss: 0.6702 - accuracy: 0.7335 - val_loss: 0.7697 - val_accuracy: 0.6787\n","Epoch 4/5\n","68/68 [==============================] - 1s 14ms/step - loss: 0.5755 - accuracy: 0.7772 - val_loss: 0.7721 - val_accuracy: 0.6799\n","Epoch 5/5\n","68/68 [==============================] - 1s 14ms/step - loss: 0.4988 - accuracy: 0.8157 - val_loss: 0.7919 - val_accuracy: 0.6760\n","Validation Accuracy: 0.6732226610183716\n","Training model with optimizer: rmsprop, epochs: 8, batch_size: 64\n","Epoch 1/8\n","272/272 [==============================] - 4s 12ms/step - loss: 0.9516 - accuracy: 0.5448 - val_loss: 0.7770 - val_accuracy: 0.6711\n","Epoch 2/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.6994 - accuracy: 0.7136 - val_loss: 0.7428 - val_accuracy: 0.6951\n","Epoch 3/8\n","272/272 [==============================] - 2s 8ms/step - loss: 0.6129 - accuracy: 0.7565 - val_loss: 0.7465 - val_accuracy: 0.6949\n","Epoch 4/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.5401 - accuracy: 0.7972 - val_loss: 0.7736 - val_accuracy: 0.6875\n","Epoch 5/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.4524 - accuracy: 0.8351 - val_loss: 0.8418 - val_accuracy: 0.6695\n","Epoch 6/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.3641 - accuracy: 0.8719 - val_loss: 0.9101 - val_accuracy: 0.6557\n","Epoch 7/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.2911 - accuracy: 0.9005 - val_loss: 1.0145 - val_accuracy: 0.6474\n","Epoch 8/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.2346 - accuracy: 0.9198 - val_loss: 1.2050 - val_accuracy: 0.6291\n","Validation Accuracy: 0.6293728947639465\n","Training model with optimizer: rmsprop, epochs: 8, batch_size: 128\n","Epoch 1/8\n","136/136 [==============================] - 2s 12ms/step - loss: 1.0274 - accuracy: 0.4741 - val_loss: 0.8646 - val_accuracy: 0.6298\n","Epoch 2/8\n","136/136 [==============================] - 1s 10ms/step - loss: 0.7383 - accuracy: 0.6954 - val_loss: 0.7721 - val_accuracy: 0.6663\n","Epoch 3/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.6209 - accuracy: 0.7543 - val_loss: 0.7444 - val_accuracy: 0.6936\n","Epoch 4/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.5410 - accuracy: 0.7913 - val_loss: 0.7707 - val_accuracy: 0.6834\n","Epoch 5/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.4623 - accuracy: 0.8292 - val_loss: 0.8349 - val_accuracy: 0.6749\n","Epoch 6/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.3866 - accuracy: 0.8636 - val_loss: 0.8952 - val_accuracy: 0.6486\n","Epoch 7/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.3161 - accuracy: 0.8918 - val_loss: 0.9455 - val_accuracy: 0.6510\n","Epoch 8/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.2584 - accuracy: 0.9152 - val_loss: 1.0626 - val_accuracy: 0.6393\n","Validation Accuracy: 0.6417862176895142\n","Training model with optimizer: rmsprop, epochs: 8, batch_size: 256\n","Epoch 1/8\n","68/68 [==============================] - 2s 16ms/step - loss: 1.0554 - accuracy: 0.4580 - val_loss: 0.9388 - val_accuracy: 0.5382\n","Epoch 2/8\n","68/68 [==============================] - 1s 12ms/step - loss: 0.8022 - accuracy: 0.6626 - val_loss: 0.7622 - val_accuracy: 0.6784\n","Epoch 3/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.6512 - accuracy: 0.7391 - val_loss: 0.7388 - val_accuracy: 0.6890\n","Epoch 4/8\n","68/68 [==============================] - 1s 11ms/step - loss: 0.5735 - accuracy: 0.7783 - val_loss: 0.7416 - val_accuracy: 0.6916\n","Epoch 5/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.5076 - accuracy: 0.8096 - val_loss: 0.7777 - val_accuracy: 0.6832\n","Epoch 6/8\n","68/68 [==============================] - 5s 77ms/step - loss: 0.4435 - accuracy: 0.8389 - val_loss: 0.8073 - val_accuracy: 0.6771\n","Epoch 7/8\n","68/68 [==============================] - 12s 172ms/step - loss: 0.3780 - accuracy: 0.8694 - val_loss: 0.8656 - val_accuracy: 0.6677\n","Epoch 8/8\n","68/68 [==============================] - 11s 169ms/step - loss: 0.3165 - accuracy: 0.8955 - val_loss: 0.9069 - val_accuracy: 0.6541\n","Validation Accuracy: 0.6545220017433167\n","Training model with optimizer: sgd, epochs: 2, batch_size: 64\n","Epoch 1/2\n","272/272 [==============================] - 79s 290ms/step - loss: 1.0864 - accuracy: 0.4046 - val_loss: 1.0849 - val_accuracy: 0.4056\n","Epoch 2/2\n","272/272 [==============================] - 79s 289ms/step - loss: 1.0849 - accuracy: 0.4046 - val_loss: 1.0833 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 2, batch_size: 128\n","Epoch 1/2\n","136/136 [==============================] - 2s 11ms/step - loss: 1.0889 - accuracy: 0.4012 - val_loss: 1.0858 - val_accuracy: 0.4056\n","Epoch 2/2\n","136/136 [==============================] - 1s 9ms/step - loss: 1.0859 - accuracy: 0.4046 - val_loss: 1.0843 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 2, batch_size: 256\n","Epoch 1/2\n","68/68 [==============================] - 2s 17ms/step - loss: 1.0899 - accuracy: 0.3985 - val_loss: 1.0858 - val_accuracy: 0.4056\n","Epoch 2/2\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0865 - accuracy: 0.4046 - val_loss: 1.0852 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 3, batch_size: 64\n","Epoch 1/3\n","272/272 [==============================] - 3s 9ms/step - loss: 1.0875 - accuracy: 0.4025 - val_loss: 1.0846 - val_accuracy: 0.4056\n","Epoch 2/3\n"," 25/272 [=>............................] - ETA: 1s - loss: 1.0887 - accuracy: 0.3938"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Evaluate the model on validation data\u001b[39;00m\n\u001b[0;32m    137\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_padded, y_test_categorical, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[1;32mc:\\Users\\91798\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","from keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","class CustomTokenizer:\n","    def __init__(self, num_words=None):\n","        self.num_words = num_words\n","        self.word_to_index = {}\n","        self.index_to_word = {}\n","        self.word_counts = {}\n","        self.index = 1  # Start index from 1 (0 reserved for padding)\n","\n","    def fit_on_texts(self, texts):\n","        for text in texts:\n","            for word in text.split():\n","                if word not in self.word_counts:\n","                    self.word_counts[word] = 1\n","                else:\n","                    self.word_counts[word] += 1\n","\n","        # Sort words by frequency and select top num_words if specified\n","        sorted_words = sorted(self.word_counts.items(), key=lambda x: x[1], reverse=True)\n","        if self.num_words:\n","            sorted_words = sorted_words[:self.num_words]\n","\n","        # Assign index to each word\n","        for word, _ in sorted_words:\n","            self.word_to_index[word] = self.index\n","            self.index_to_word[self.index] = word\n","            self.index += 1\n","\n","    def texts_to_sequences(self, texts):\n","        sequences = []\n","        for text in texts:\n","            sequence = [self.word_to_index[word] for word in text.split() if word in self.word_to_index]\n","            sequences.append(sequence)\n","        return sequences\n","\n","\n","\n","# Define a custom preprocessing function\n","def preprocess_text(text):\n","    # Convert text to lowercase\n","    text = text.lower()\n","    # Remove special characters, punctuation, and numbers\n","    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n","    # Tokenize the text\n","    tokens = nltk.word_tokenize(text)\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    # Join tokens back into a string\n","    clean_text = \" \".join(tokens)\n","    return clean_text\n","import pandas as pd\n","\n","df1 = pd.read_csv('train.csv',encoding='latin1')\n","df2 = pd.read_csv('test.csv',encoding='latin1')\n","\n","# Merge the DataFrames\n","twitter_data = pd.concat([df1, df2], ignore_index=True)\n","\n","# Write the merged DataFrame to a new CSV file\n","twitter_data.to_csv('merged_file.csv', index=False)\n","\n","# Drop rows with NaN or null values in the 'text' column\n","twitter_data.dropna(subset=['text'], inplace=True)\n","\n","# Apply the preprocessing function to the 'text' column\n","twitter_data['text'] = twitter_data['text'].apply(preprocess_text)\n","\n","# Create an instance of CustomTokenizer\n","custom_tokenizer = CustomTokenizer(num_words=5000)\n","custom_tokenizer.fit_on_texts(twitter_data['text'])\n","\n","# Convert sentiment labels to numeric form\n","sentiment_mapping = {'neutral': 0, 'positive': 1, 'negative': 2}\n","twitter_data['sentiment_encoded'] = twitter_data['sentiment'].map(sentiment_mapping)\n","\n","# Split the dataset into training and testing sets\n","X = twitter_data['text']\n","y = twitter_data['sentiment_encoded']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert texts to sequences\n","X_train_seq = custom_tokenizer.texts_to_sequences(X_train)\n","X_test_seq = custom_tokenizer.texts_to_sequences(X_test)\n","\n","# Pad sequences to ensure uniform length\n","maxlen = 100\n","X_train_padded = pad_sequences(X_train_seq, maxlen=maxlen)\n","X_test_padded = pad_sequences(X_test_seq, maxlen=maxlen)\n","\n","# Convert labels to categorical format\n","y_train_categorical = to_categorical(y_train)\n","y_test_categorical = to_categorical(y_test)\n","\n","# Define a function to create the model with specified hyperparameters\n","def create_model(optimizer='adam'):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=len(custom_tokenizer.word_to_index) + 1, output_dim=100, input_length=maxlen))\n","    model.add(Flatten())\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Define the hyperparameters to tune\n","optimizers = ['adam', 'rmsprop', 'sgd']\n","epochs_list = [2,3, 5, 8]\n","batch_sizes = [64, 128, 256]\n","\n","# Perform hyperparameter tuning\n","best_accuracy = 0\n","best_hyperparameters = {}\n","\n","for optimizer in optimizers:\n","    for epochs in epochs_list:\n","        for batch_size in batch_sizes:\n","            print(f\"Training model with optimizer: {optimizer}, epochs: {epochs}, batch_size: {batch_size}\")\n","            \n","            # Create and compile the model with current hyperparameters\n","            model = create_model(optimizer=optimizer)\n","            \n","            # Train the model\n","            history = model.fit(X_train_padded, y_train_categorical, epochs=epochs, batch_size=batch_size, validation_split=0.3, verbose=1)\n","            \n","            # Evaluate the model on validation data\n","            _, accuracy = model.evaluate(X_test_padded, y_test_categorical, verbose=0)\n","            print(f\"Validation Accuracy: {accuracy}\")\n","            \n","            # Update best accuracy and hyperparameters if needed\n","            if accuracy > best_accuracy:\n","                best_accuracy = accuracy\n","                best_hyperparameters = {'optimizer': optimizer, 'epochs': epochs, 'batch_size': batch_size}\n","\n","print(\"Best hyperparameters:\", best_hyperparameters)\n","print(\"Best validation accuracy:\", best_accuracy)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":989445,"sourceId":1808590,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
