{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing ANN Implementation"]},{"cell_type":"markdown","metadata":{},"source":["Importing Dataset and Combining "]},{"cell_type":"code","execution_count":26,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-19T01:37:34.343690Z","iopub.status.busy":"2024-04-19T01:37:34.343230Z","iopub.status.idle":"2024-04-19T01:37:34.947398Z","shell.execute_reply":"2024-04-19T01:37:34.945434Z","shell.execute_reply.started":"2024-04-19T01:37:34.343658Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["       textID                                               text  \\\n","0  cb774db0d1                I`d have responded, if I were going   \n","1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2  088c60f138                          my boss is bullying me...   \n","3  9642c003ef                     what interview! leave me alone   \n","4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","\n","                         selected_text sentiment Time of Tweet Age of User  \\\n","0  I`d have responded, if I were going   neutral       morning        0-20   \n","1                             Sooo SAD  negative          noon       21-30   \n","2                          bullying me  negative         night       31-45   \n","3                       leave me alone  negative       morning       46-60   \n","4                        Sons of ****,  negative          noon       60-70   \n","\n","       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n","0  Afghanistan        38928346.0         652860.0             60.0  \n","1      Albania         2877797.0          27400.0            105.0  \n","2      Algeria        43851044.0        2381740.0             18.0  \n","3      Andorra           77265.0            470.0            164.0  \n","4       Angola        32866272.0        1246700.0             26.0  \n"]}],"source":["import pandas as pd\n","\n","df1 = pd.read_csv('train.csv',encoding='latin1')\n","df2 = pd.read_csv('test.csv',encoding='latin1')\n","\n","# Merge the DataFrames\n","train_data = pd.concat([df1, df2], ignore_index=True)\n","\n","# Write the merged DataFrame to a new CSV file\n","train_data.to_csv('merged_file.csv', index=False)\n","print(train_data.head())\n"]},{"cell_type":"markdown","metadata":{},"source":["Removing the Unnecessary columns"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:39.371712Z","iopub.status.busy":"2024-04-19T01:37:39.370463Z","iopub.status.idle":"2024-04-19T01:37:39.382078Z","shell.execute_reply":"2024-04-19T01:37:39.380404Z","shell.execute_reply.started":"2024-04-19T01:37:39.371677Z"},"trusted":true},"outputs":[],"source":["columns_to_remove = ['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n","train_data.drop(columns=columns_to_remove, inplace=True)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:42.065849Z","iopub.status.busy":"2024-04-19T01:37:42.065069Z","iopub.status.idle":"2024-04-19T01:37:42.080171Z","shell.execute_reply":"2024-04-19T01:37:42.079026Z","shell.execute_reply.started":"2024-04-19T01:37:42.065803Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32291</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32292</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32293</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32294</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32295</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32296 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                    I`d have responded, if I were going   neutral\n","1          Sooo SAD I will miss you here in San Diego!!!  negative\n","2                              my boss is bullying me...  negative\n","3                         what interview! leave me alone  negative\n","4       Sons of ****, why couldn`t they put them on t...  negative\n","...                                                  ...       ...\n","32291                                                NaN       NaN\n","32292                                                NaN       NaN\n","32293                                                NaN       NaN\n","32294                                                NaN       NaN\n","32295                                                NaN       NaN\n","\n","[32296 rows x 2 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:45.393561Z","iopub.status.busy":"2024-04-19T01:37:45.393032Z","iopub.status.idle":"2024-04-19T01:37:45.434840Z","shell.execute_reply":"2024-04-19T01:37:45.433152Z","shell.execute_reply.started":"2024-04-19T01:37:45.393509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing Values:\n"," text         1282\n","sentiment    1281\n","dtype: int64\n","\n","Duplicate Rows: 1280\n"]}],"source":["# Check for missing values\n","missing_values = train_data.isnull().sum()\n","print(\"Missing Values:\\n\", missing_values)\n","\n","# Check for duplicates\n","duplicate_rows = train_data.duplicated().sum()\n","print(\"\\nDuplicate Rows:\", duplicate_rows)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:48.121570Z","iopub.status.busy":"2024-04-19T01:37:48.121153Z","iopub.status.idle":"2024-04-19T01:37:48.137707Z","shell.execute_reply":"2024-04-19T01:37:48.135593Z","shell.execute_reply.started":"2024-04-19T01:37:48.121540Z"},"trusted":true},"outputs":[],"source":["train_data.dropna(subset=['text'], inplace=True)\n","# train_data.dropna(subset=['text_lower'],inplace=True)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:50.965382Z","iopub.status.busy":"2024-04-19T01:37:50.964966Z","iopub.status.idle":"2024-04-19T01:37:50.983116Z","shell.execute_reply":"2024-04-19T01:37:50.981600Z","shell.execute_reply.started":"2024-04-19T01:37:50.965355Z"},"trusted":true},"outputs":[],"source":["# Lowercase Conversion\n","train_data['text'] = train_data['text'].str.lower()\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:01.703114Z","iopub.status.busy":"2024-04-19T01:38:01.702690Z","iopub.status.idle":"2024-04-19T01:38:01.718499Z","shell.execute_reply":"2024-04-19T01:38:01.717036Z","shell.execute_reply.started":"2024-04-19T01:38:01.703084Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>i`d have responded, if i were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego!!!</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>all alone in this old house again.  thanks for...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>i know what you mean. my little dog is sinkin...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                    i`d have responded, if i were going   neutral\n","1          sooo sad i will miss you here in san diego!!!  negative\n","2                              my boss is bullying me...  negative\n","3                         what interview! leave me alone  negative\n","4       sons of ****, why couldn`t they put them on t...  negative\n","...                                                  ...       ...\n","31010  its at 3 am, im very tired but i can`t sleep  ...  negative\n","31011  all alone in this old house again.  thanks for...  positive\n","31012   i know what you mean. my little dog is sinkin...  negative\n","31013  _sutra what is your next youtube video gonna b...  positive\n","31014   http://twitpic.com/4woj2 - omgssh  ang cute n...  positive\n","\n","[31014 rows x 2 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["*****Text cleaning***"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:08.468825Z","iopub.status.busy":"2024-04-19T01:38:08.468377Z","iopub.status.idle":"2024-04-19T01:38:08.794800Z","shell.execute_reply":"2024-04-19T01:38:08.793373Z","shell.execute_reply.started":"2024-04-19T01:38:08.468796Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of  why couldnt they put them on the rel...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am im very tired but i cant sleep  bu...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>all alone in this old house again  thanks for ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>i know what you mean my little dog is sinking...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>sutra what is your next youtube video gonna be...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>omgssh  ang cute ng bby</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                      id have responded if i were going   neutral\n","1             sooo sad i will miss you here in san diego  negative\n","2                                 my boss is bullying me  negative\n","3                          what interview leave me alone  negative\n","4       sons of  why couldnt they put them on the rel...  negative\n","...                                                  ...       ...\n","31010  its at 3 am im very tired but i cant sleep  bu...  negative\n","31011  all alone in this old house again  thanks for ...  positive\n","31012   i know what you mean my little dog is sinking...  negative\n","31013  sutra what is your next youtube video gonna be...  positive\n","31014                            omgssh  ang cute ng bby  positive\n","\n","[31014 rows x 2 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","\n","def clean_text(text):\n","    if isinstance(text, str):  # Check if text is a string\n","        # Remove special characters, HTML tags, and links\n","        cleaned_text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n","        cleaned_text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", cleaned_text)  # Remove links\n","        cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # Remove special characters\n","        return cleaned_text.lower()  # Convert text to lowercase\n","    else:\n","        return text  # Return unchanged if not a string\n","\n","# Apply text cleaning to 'text' column\n","train_data['text'] = train_data['text'].apply(clean_text)\n","train_data"]},{"cell_type":"markdown","metadata":{},"source":["**Stopwords Removal: Remove common stopwords while preserving the links.**"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:22.060730Z","iopub.status.busy":"2024-04-19T01:38:22.060261Z","iopub.status.idle":"2024-04-19T01:38:27.306346Z","shell.execute_reply":"2024-04-19T01:38:27.304969Z","shell.execute_reply.started":"2024-04-19T01:38:22.060699Z"},"trusted":true},"outputs":[],"source":["import requests\n","\n","# Download the stopwords file\n","url = \"https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\"\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Extract stopwords from the content\n","    stopwords = response.text.split(\",\")\n","else:\n","    print(\"Failed to download stopwords file.\")\n","\n","# Stopwords removal function\n","def remove_stopwords(text):\n","    if isinstance(text, str):\n","        # Split the text into tokens using whitespace as delimiter\n","        tokens = text.split()\n","        # Remove stopwords from the tokens\n","        filtered_tokens = [word for word in tokens if word.lower() not in stopwords]\n","        # Join the filtered tokens back into a string\n","        filtered_text = ' '.join(filtered_tokens)\n","        return filtered_text\n","    else:\n","        return text\n","\n","\n","\n","\n","\n","# Applying the stopwords removal function to the 'text' column in the train_data DataFrame\n","train_data['text'] = train_data['text'].apply(remove_stopwords)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:33.731014Z","iopub.status.busy":"2024-04-19T01:38:33.730511Z","iopub.status.idle":"2024-04-19T01:38:33.753932Z","shell.execute_reply":"2024-04-19T01:38:33.753033Z","shell.execute_reply.started":"2024-04-19T01:38:33.730981Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>responded</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad san diego</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>boss bullying</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>interview leave</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons releases bought</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>3 tired sleep</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>house net alive kicking invented net wanna kis...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>dog sinking depression someplace tropical</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>sutra youtube video gonna love videos</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>omgssh ang cute bby</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                                              responded   neutral\n","1                                     sooo sad san diego  negative\n","2                                          boss bullying  negative\n","3                                        interview leave  negative\n","4                                   sons releases bought  negative\n","...                                                  ...       ...\n","31010                                      3 tired sleep  negative\n","31011  house net alive kicking invented net wanna kis...  positive\n","31012          dog sinking depression someplace tropical  negative\n","31013              sutra youtube video gonna love videos  positive\n","31014                                omgssh ang cute bby  positive\n","\n","[31014 rows x 2 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:48:34.702502Z","iopub.status.busy":"2024-04-19T01:48:34.700655Z","iopub.status.idle":"2024-04-19T01:48:34.722585Z","shell.execute_reply":"2024-04-19T01:48:34.721428Z","shell.execute_reply.started":"2024-04-19T01:48:34.702432Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Encode the sentiment labels\n","label_encoder = LabelEncoder()\n","train_data['sentiment'] = label_encoder.fit_transform(train_data['sentiment'])\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["class CustomTokenizer:\n","    def __init__(self, num_words=None):\n","        self.num_words = num_words\n","        self.word_to_index = {}\n","        self.index_to_word = {}\n","        self.word_counts = {}\n","        self.index = 1  # Start index from 1 (0 reserved for padding)\n","\n","    def fit_on_texts(self, texts):\n","        for text in texts:\n","            for word in text.split():\n","                if word not in self.word_counts:\n","                    self.word_counts[word] = 1\n","                else:\n","                    self.word_counts[word] += 1\n","\n","        # Sort words by frequency and select top num_words if specified\n","        sorted_words = sorted(self.word_counts.items(), key=lambda x: x[1], reverse=True)\n","        if self.num_words:\n","            sorted_words = sorted_words[:self.num_words]\n","\n","        # Assign index to each word\n","        for word, _ in sorted_words:\n","            self.word_to_index[word] = self.index\n","            self.index_to_word[self.index] = word\n","            self.index += 1\n","\n","    def texts_to_sequences(self, texts):\n","        sequences = []\n","        for text in texts:\n","            sequence = [self.word_to_index[word] for word in text.split() if word in self.word_to_index]\n","            sequences.append(sequence)\n","        return sequences\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Final Python Script with all the implementations"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model with optimizer: adam, epochs: 2, batch_size: 64\n","Epoch 1/2\n","272/272 [==============================] - 88s 322ms/step - loss: 0.9532 - accuracy: 0.5259 - val_loss: 0.7859 - val_accuracy: 0.6634\n","Epoch 2/2\n","272/272 [==============================] - 40s 146ms/step - loss: 0.6639 - accuracy: 0.7272 - val_loss: 0.7413 - val_accuracy: 0.6891\n","Validation Accuracy: 0.6814444661140442\n","Training model with optimizer: adam, epochs: 2, batch_size: 128\n","Epoch 1/2\n","136/136 [==============================] - 2s 9ms/step - loss: 1.0190 - accuracy: 0.4836 - val_loss: 0.8675 - val_accuracy: 0.6459\n","Epoch 2/2\n","136/136 [==============================] - 1s 7ms/step - loss: 0.7010 - accuracy: 0.7174 - val_loss: 0.7418 - val_accuracy: 0.6882\n","Validation Accuracy: 0.6809608340263367\n","Training model with optimizer: adam, epochs: 2, batch_size: 256\n","Epoch 1/2\n","68/68 [==============================] - 2s 16ms/step - loss: 1.0521 - accuracy: 0.4416 - val_loss: 0.9478 - val_accuracy: 0.5840\n","Epoch 2/2\n","68/68 [==============================] - 1s 13ms/step - loss: 0.7832 - accuracy: 0.6697 - val_loss: 0.7528 - val_accuracy: 0.6815\n","Validation Accuracy: 0.6712880730628967\n","Training model with optimizer: adam, epochs: 3, batch_size: 64\n","Epoch 1/3\n","272/272 [==============================] - 3s 9ms/step - loss: 0.9418 - accuracy: 0.5403 - val_loss: 0.7672 - val_accuracy: 0.6812\n","Epoch 2/3\n","272/272 [==============================] - 2s 8ms/step - loss: 0.6335 - accuracy: 0.7474 - val_loss: 0.7541 - val_accuracy: 0.6871\n","Epoch 3/3\n","272/272 [==============================] - 2s 7ms/step - loss: 0.4613 - accuracy: 0.8313 - val_loss: 0.8269 - val_accuracy: 0.6652\n","Validation Accuracy: 0.6619377732276917\n","Training model with optimizer: adam, epochs: 3, batch_size: 128\n","Epoch 1/3\n","136/136 [==============================] - 2s 9ms/step - loss: 0.9861 - accuracy: 0.5073 - val_loss: 0.7855 - val_accuracy: 0.6640\n","Epoch 2/3\n","136/136 [==============================] - 1s 8ms/step - loss: 0.6697 - accuracy: 0.7302 - val_loss: 0.7400 - val_accuracy: 0.6894\n","Epoch 3/3\n","136/136 [==============================] - 1s 8ms/step - loss: 0.5171 - accuracy: 0.8050 - val_loss: 0.7869 - val_accuracy: 0.6779\n","Validation Accuracy: 0.6729001998901367\n","Training model with optimizer: adam, epochs: 3, batch_size: 256\n","Epoch 1/3\n","68/68 [==============================] - 2s 20ms/step - loss: 1.0900 - accuracy: 0.3946 - val_loss: 1.0764 - val_accuracy: 0.4056\n","Epoch 2/3\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0380 - accuracy: 0.4654 - val_loss: 0.9802 - val_accuracy: 0.5574\n","Epoch 3/3\n","68/68 [==============================] - 1s 11ms/step - loss: 0.8480 - accuracy: 0.5896 - val_loss: 0.8376 - val_accuracy: 0.5942\n","Validation Accuracy: 0.5842334628105164\n","Training model with optimizer: adam, epochs: 5, batch_size: 64\n","Epoch 1/5\n","272/272 [==============================] - 2s 8ms/step - loss: 0.9232 - accuracy: 0.5540 - val_loss: 0.7586 - val_accuracy: 0.6816\n","Epoch 2/5\n","272/272 [==============================] - 2s 7ms/step - loss: 0.6590 - accuracy: 0.7314 - val_loss: 0.7388 - val_accuracy: 0.6961\n","Epoch 3/5\n","272/272 [==============================] - 2s 9ms/step - loss: 0.5107 - accuracy: 0.8068 - val_loss: 0.7987 - val_accuracy: 0.6842\n","Epoch 4/5\n","272/272 [==============================] - 2s 8ms/step - loss: 0.3708 - accuracy: 0.8723 - val_loss: 0.9498 - val_accuracy: 0.6604\n","Epoch 5/5\n","272/272 [==============================] - 2s 9ms/step - loss: 0.2572 - accuracy: 0.9178 - val_loss: 1.0589 - val_accuracy: 0.6471\n","Validation Accuracy: 0.6482347249984741\n","Training model with optimizer: adam, epochs: 5, batch_size: 128\n","Epoch 1/5\n","136/136 [==============================] - 2s 10ms/step - loss: 1.0359 - accuracy: 0.4672 - val_loss: 0.9013 - val_accuracy: 0.6100\n","Epoch 2/5\n","136/136 [==============================] - 1s 8ms/step - loss: 0.7333 - accuracy: 0.7025 - val_loss: 0.7487 - val_accuracy: 0.6835\n","Epoch 3/5\n","136/136 [==============================] - 1s 8ms/step - loss: 0.5528 - accuracy: 0.7883 - val_loss: 0.7704 - val_accuracy: 0.6863\n","Epoch 4/5\n","136/136 [==============================] - 1s 8ms/step - loss: 0.4265 - accuracy: 0.8502 - val_loss: 0.8725 - val_accuracy: 0.6562\n","Epoch 5/5\n","136/136 [==============================] - 1s 9ms/step - loss: 0.3162 - accuracy: 0.8974 - val_loss: 0.9686 - val_accuracy: 0.6487\n","Validation Accuracy: 0.6469449996948242\n","Training model with optimizer: adam, epochs: 5, batch_size: 256\n","Epoch 1/5\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0794 - accuracy: 0.4195 - val_loss: 1.0436 - val_accuracy: 0.4663\n","Epoch 2/5\n","68/68 [==============================] - 1s 11ms/step - loss: 0.9566 - accuracy: 0.5516 - val_loss: 0.8961 - val_accuracy: 0.6046\n","Epoch 3/5\n","68/68 [==============================] - 1s 11ms/step - loss: 0.7461 - accuracy: 0.7090 - val_loss: 0.7869 - val_accuracy: 0.6725\n","Epoch 4/5\n","68/68 [==============================] - 1s 11ms/step - loss: 0.5851 - accuracy: 0.7814 - val_loss: 0.7780 - val_accuracy: 0.6783\n","Epoch 5/5\n","68/68 [==============================] - 1s 11ms/step - loss: 0.4807 - accuracy: 0.8278 - val_loss: 0.7959 - val_accuracy: 0.6771\n","Validation Accuracy: 0.6680638194084167\n","Training model with optimizer: adam, epochs: 8, batch_size: 64\n","Epoch 1/8\n","272/272 [==============================] - 3s 8ms/step - loss: 0.9480 - accuracy: 0.5312 - val_loss: 0.7832 - val_accuracy: 0.6697\n","Epoch 2/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.6909 - accuracy: 0.7218 - val_loss: 0.7519 - val_accuracy: 0.6873\n","Epoch 3/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.5498 - accuracy: 0.7883 - val_loss: 0.7824 - val_accuracy: 0.6852\n","Epoch 4/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.4193 - accuracy: 0.8505 - val_loss: 0.8711 - val_accuracy: 0.6693\n","Epoch 5/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.3048 - accuracy: 0.8986 - val_loss: 0.9872 - val_accuracy: 0.6542\n","Epoch 6/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.2161 - accuracy: 0.9333 - val_loss: 1.1328 - val_accuracy: 0.6491\n","Epoch 7/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.1549 - accuracy: 0.9523 - val_loss: 1.2852 - val_accuracy: 0.6401\n","Epoch 8/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.1165 - accuracy: 0.9657 - val_loss: 1.4392 - val_accuracy: 0.6370\n","Validation Accuracy: 0.6445268392562866\n","Training model with optimizer: adam, epochs: 8, batch_size: 128\n","Epoch 1/8\n","136/136 [==============================] - 2s 9ms/step - loss: 1.0072 - accuracy: 0.4753 - val_loss: 0.8343 - val_accuracy: 0.6014\n","Epoch 2/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.7084 - accuracy: 0.7087 - val_loss: 0.7330 - val_accuracy: 0.6906\n","Epoch 3/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.5539 - accuracy: 0.7884 - val_loss: 0.7700 - val_accuracy: 0.6847\n","Epoch 4/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.4377 - accuracy: 0.8405 - val_loss: 0.8278 - val_accuracy: 0.6714\n","Epoch 5/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.3293 - accuracy: 0.8913 - val_loss: 0.9313 - val_accuracy: 0.6650\n","Epoch 6/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.2407 - accuracy: 0.9269 - val_loss: 1.0310 - val_accuracy: 0.6499\n","Epoch 7/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.1791 - accuracy: 0.9479 - val_loss: 1.1768 - val_accuracy: 0.6435\n","Epoch 8/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.1395 - accuracy: 0.9598 - val_loss: 1.2628 - val_accuracy: 0.6374\n","Validation Accuracy: 0.6359825730323792\n","Training model with optimizer: adam, epochs: 8, batch_size: 256\n","Epoch 1/8\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0546 - accuracy: 0.4480 - val_loss: 0.9545 - val_accuracy: 0.5446\n","Epoch 2/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.8162 - accuracy: 0.6291 - val_loss: 0.7628 - val_accuracy: 0.6733\n","Epoch 3/8\n","68/68 [==============================] - 1s 11ms/step - loss: 0.6171 - accuracy: 0.7589 - val_loss: 0.7459 - val_accuracy: 0.6922\n","Epoch 4/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.4983 - accuracy: 0.8157 - val_loss: 0.7831 - val_accuracy: 0.6784\n","Epoch 5/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.3987 - accuracy: 0.8603 - val_loss: 0.8570 - val_accuracy: 0.6651\n","Epoch 6/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.3056 - accuracy: 0.9027 - val_loss: 0.9504 - val_accuracy: 0.6525\n","Epoch 7/8\n","68/68 [==============================] - 1s 12ms/step - loss: 0.2339 - accuracy: 0.9317 - val_loss: 1.0368 - val_accuracy: 0.6377\n","Epoch 8/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.1786 - accuracy: 0.9498 - val_loss: 1.1718 - val_accuracy: 0.6346\n","Validation Accuracy: 0.633725643157959\n","Training model with optimizer: rmsprop, epochs: 2, batch_size: 64\n","Epoch 1/2\n","272/272 [==============================] - 3s 7ms/step - loss: 0.9262 - accuracy: 0.5557 - val_loss: 0.7611 - val_accuracy: 0.6772\n","Epoch 2/2\n","272/272 [==============================] - 2s 7ms/step - loss: 0.6858 - accuracy: 0.7210 - val_loss: 0.7447 - val_accuracy: 0.6865\n","Validation Accuracy: 0.6806383728981018\n","Training model with optimizer: rmsprop, epochs: 2, batch_size: 128\n","Epoch 1/2\n","136/136 [==============================] - 2s 9ms/step - loss: 0.9997 - accuracy: 0.5053 - val_loss: 0.8279 - val_accuracy: 0.6597\n","Epoch 2/2\n","136/136 [==============================] - 1s 8ms/step - loss: 0.7199 - accuracy: 0.7051 - val_loss: 0.7443 - val_accuracy: 0.6908\n","Validation Accuracy: 0.6883766055107117\n","Training model with optimizer: rmsprop, epochs: 2, batch_size: 256\n","Epoch 1/2\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0655 - accuracy: 0.4436 - val_loss: 0.9564 - val_accuracy: 0.5944\n","Epoch 2/2\n","68/68 [==============================] - 1s 11ms/step - loss: 0.8258 - accuracy: 0.6546 - val_loss: 0.7733 - val_accuracy: 0.6623\n","Validation Accuracy: 0.6540383696556091\n","Training model with optimizer: rmsprop, epochs: 3, batch_size: 64\n","Epoch 1/3\n","272/272 [==============================] - 2s 7ms/step - loss: 0.9620 - accuracy: 0.5267 - val_loss: 0.8098 - val_accuracy: 0.6546\n","Epoch 2/3\n","272/272 [==============================] - 3s 12ms/step - loss: 0.7010 - accuracy: 0.7132 - val_loss: 0.7334 - val_accuracy: 0.6957\n","Epoch 3/3\n","272/272 [==============================] - 4s 15ms/step - loss: 0.5946 - accuracy: 0.7659 - val_loss: 0.7673 - val_accuracy: 0.6787\n","Validation Accuracy: 0.6767693161964417\n","Training model with optimizer: rmsprop, epochs: 3, batch_size: 128\n","Epoch 1/3\n","136/136 [==============================] - 2s 9ms/step - loss: 0.9644 - accuracy: 0.5280 - val_loss: 0.7887 - val_accuracy: 0.6690\n","Epoch 2/3\n","136/136 [==============================] - 1s 8ms/step - loss: 0.6952 - accuracy: 0.7181 - val_loss: 0.7505 - val_accuracy: 0.6839\n","Epoch 3/3\n","136/136 [==============================] - 1s 8ms/step - loss: 0.5872 - accuracy: 0.7719 - val_loss: 0.7613 - val_accuracy: 0.6869\n","Validation Accuracy: 0.6874093413352966\n","Training model with optimizer: rmsprop, epochs: 3, batch_size: 256\n","Epoch 1/3\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0491 - accuracy: 0.4620 - val_loss: 0.9219 - val_accuracy: 0.5673\n","Epoch 2/3\n","68/68 [==============================] - 1s 11ms/step - loss: 0.7966 - accuracy: 0.6656 - val_loss: 0.7612 - val_accuracy: 0.6705\n","Epoch 3/3\n","68/68 [==============================] - 1s 10ms/step - loss: 0.6450 - accuracy: 0.7417 - val_loss: 0.7375 - val_accuracy: 0.6916\n","Validation Accuracy: 0.6891826391220093\n","Training model with optimizer: rmsprop, epochs: 5, batch_size: 64\n","Epoch 1/5\n","272/272 [==============================] - 3s 9ms/step - loss: 0.9954 - accuracy: 0.5142 - val_loss: 0.8246 - val_accuracy: 0.6259\n","Epoch 2/5\n","272/272 [==============================] - 2s 7ms/step - loss: 0.7111 - accuracy: 0.7096 - val_loss: 0.7457 - val_accuracy: 0.6921\n","Epoch 3/5\n","272/272 [==============================] - 39s 144ms/step - loss: 0.6063 - accuracy: 0.7614 - val_loss: 0.7600 - val_accuracy: 0.6902\n","Epoch 4/5\n","272/272 [==============================] - 81s 298ms/step - loss: 0.5190 - accuracy: 0.8033 - val_loss: 0.8312 - val_accuracy: 0.6627\n","Epoch 5/5\n","272/272 [==============================] - 39s 142ms/step - loss: 0.4238 - accuracy: 0.8458 - val_loss: 0.8576 - val_accuracy: 0.6685\n","Validation Accuracy: 0.6633886694908142\n","Training model with optimizer: rmsprop, epochs: 5, batch_size: 128\n","Epoch 1/5\n","136/136 [==============================] - 2s 8ms/step - loss: 1.0100 - accuracy: 0.4919 - val_loss: 0.8313 - val_accuracy: 0.6427\n","Epoch 2/5\n","136/136 [==============================] - 1s 8ms/step - loss: 0.7290 - accuracy: 0.7001 - val_loss: 0.7335 - val_accuracy: 0.6902\n","Epoch 3/5\n","136/136 [==============================] - 1s 7ms/step - loss: 0.6234 - accuracy: 0.7525 - val_loss: 0.7444 - val_accuracy: 0.6951\n","Epoch 4/5\n","136/136 [==============================] - 1s 8ms/step - loss: 0.5549 - accuracy: 0.7856 - val_loss: 0.7496 - val_accuracy: 0.6951\n","Epoch 5/5\n","136/136 [==============================] - 1s 9ms/step - loss: 0.4887 - accuracy: 0.8167 - val_loss: 0.7731 - val_accuracy: 0.6881\n","Validation Accuracy: 0.6845074892044067\n","Training model with optimizer: rmsprop, epochs: 5, batch_size: 256\n","Epoch 1/5\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0656 - accuracy: 0.4371 - val_loss: 0.9558 - val_accuracy: 0.5528\n","Epoch 2/5\n","68/68 [==============================] - 1s 11ms/step - loss: 0.8518 - accuracy: 0.6028 - val_loss: 0.7926 - val_accuracy: 0.6796\n","Epoch 3/5\n","68/68 [==============================] - 1s 10ms/step - loss: 0.7035 - accuracy: 0.7183 - val_loss: 0.7406 - val_accuracy: 0.6921\n","Epoch 4/5\n","68/68 [==============================] - 1s 10ms/step - loss: 0.6226 - accuracy: 0.7573 - val_loss: 0.7466 - val_accuracy: 0.6854\n","Epoch 5/5\n","68/68 [==============================] - 1s 10ms/step - loss: 0.5657 - accuracy: 0.7844 - val_loss: 0.7433 - val_accuracy: 0.6963\n","Validation Accuracy: 0.6917620301246643\n","Training model with optimizer: rmsprop, epochs: 8, batch_size: 64\n","Epoch 1/8\n","272/272 [==============================] - 3s 8ms/step - loss: 0.9341 - accuracy: 0.5500 - val_loss: 0.7972 - val_accuracy: 0.6604\n","Epoch 2/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.6936 - accuracy: 0.7173 - val_loss: 0.7393 - val_accuracy: 0.6947\n","Epoch 3/8\n","272/272 [==============================] - 2s 7ms/step - loss: 0.6037 - accuracy: 0.7637 - val_loss: 0.7692 - val_accuracy: 0.6904\n","Epoch 4/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.5166 - accuracy: 0.8075 - val_loss: 0.7853 - val_accuracy: 0.6792\n","Epoch 5/8\n","272/272 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8508 - val_loss: 0.8593 - val_accuracy: 0.6605\n","Epoch 6/8\n","272/272 [==============================] - 2s 8ms/step - loss: 0.3309 - accuracy: 0.8848 - val_loss: 0.9429 - val_accuracy: 0.6509\n","Epoch 7/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.2614 - accuracy: 0.9092 - val_loss: 1.0957 - val_accuracy: 0.6354\n","Epoch 8/8\n","272/272 [==============================] - 2s 6ms/step - loss: 0.2122 - accuracy: 0.9255 - val_loss: 1.2270 - val_accuracy: 0.6343\n","Validation Accuracy: 0.6334031820297241\n","Training model with optimizer: rmsprop, epochs: 8, batch_size: 128\n","Epoch 1/8\n","136/136 [==============================] - 2s 8ms/step - loss: 0.9859 - accuracy: 0.5080 - val_loss: 0.7989 - val_accuracy: 0.6701\n","Epoch 2/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.7053 - accuracy: 0.7144 - val_loss: 0.7333 - val_accuracy: 0.7014\n","Epoch 3/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.6000 - accuracy: 0.7643 - val_loss: 0.7442 - val_accuracy: 0.6930\n","Epoch 4/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.5107 - accuracy: 0.8087 - val_loss: 0.7793 - val_accuracy: 0.6801\n","Epoch 5/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.8497 - val_loss: 0.8416 - val_accuracy: 0.6690\n","Epoch 6/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.3347 - accuracy: 0.8841 - val_loss: 0.9417 - val_accuracy: 0.6535\n","Epoch 7/8\n","136/136 [==============================] - 1s 8ms/step - loss: 0.2658 - accuracy: 0.9102 - val_loss: 1.0429 - val_accuracy: 0.6424\n","Epoch 8/8\n","136/136 [==============================] - 1s 7ms/step - loss: 0.2118 - accuracy: 0.9282 - val_loss: 1.1961 - val_accuracy: 0.6252\n","Validation Accuracy: 0.6292116641998291\n","Training model with optimizer: rmsprop, epochs: 8, batch_size: 256\n","Epoch 1/8\n","68/68 [==============================] - 1s 12ms/step - loss: 1.0791 - accuracy: 0.4293 - val_loss: 1.0181 - val_accuracy: 0.5907\n","Epoch 2/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.8662 - accuracy: 0.6376 - val_loss: 0.7929 - val_accuracy: 0.6690\n","Epoch 3/8\n","68/68 [==============================] - 1s 11ms/step - loss: 0.6732 - accuracy: 0.7300 - val_loss: 0.7427 - val_accuracy: 0.6894\n","Epoch 4/8\n","68/68 [==============================] - 1s 11ms/step - loss: 0.5816 - accuracy: 0.7737 - val_loss: 0.7414 - val_accuracy: 0.6936\n","Epoch 5/8\n","68/68 [==============================] - 1s 11ms/step - loss: 0.5114 - accuracy: 0.8062 - val_loss: 0.7652 - val_accuracy: 0.6822\n","Epoch 6/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.4431 - accuracy: 0.8401 - val_loss: 0.8024 - val_accuracy: 0.6754\n","Epoch 7/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.3774 - accuracy: 0.8692 - val_loss: 0.8537 - val_accuracy: 0.6499\n","Epoch 8/8\n","68/68 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.8937 - val_loss: 0.9113 - val_accuracy: 0.6491\n","Validation Accuracy: 0.6508141160011292\n","Training model with optimizer: sgd, epochs: 2, batch_size: 64\n","Epoch 1/2\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0877 - accuracy: 0.4027 - val_loss: 1.0848 - val_accuracy: 0.4056\n","Epoch 2/2\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0855 - accuracy: 0.4046 - val_loss: 1.0840 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 2, batch_size: 128\n","Epoch 1/2\n","136/136 [==============================] - 1s 9ms/step - loss: 1.0885 - accuracy: 0.3998 - val_loss: 1.0853 - val_accuracy: 0.4056\n","Epoch 2/2\n","136/136 [==============================] - 1s 8ms/step - loss: 1.0862 - accuracy: 0.4046 - val_loss: 1.0847 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 2, batch_size: 256\n","Epoch 1/2\n","68/68 [==============================] - 1s 15ms/step - loss: 1.0905 - accuracy: 0.4005 - val_loss: 1.0864 - val_accuracy: 0.4056\n","Epoch 2/2\n","68/68 [==============================] - 1s 12ms/step - loss: 1.0866 - accuracy: 0.4046 - val_loss: 1.0850 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 3, batch_size: 64\n","Epoch 1/3\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0869 - accuracy: 0.4046 - val_loss: 1.0846 - val_accuracy: 0.4056\n","Epoch 2/3\n","272/272 [==============================] - 2s 6ms/step - loss: 1.0852 - accuracy: 0.4046 - val_loss: 1.0838 - val_accuracy: 0.4056\n","Epoch 3/3\n","272/272 [==============================] - 2s 6ms/step - loss: 1.0841 - accuracy: 0.4046 - val_loss: 1.0835 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 3, batch_size: 128\n","Epoch 1/3\n","136/136 [==============================] - 2s 9ms/step - loss: 1.0873 - accuracy: 0.4046 - val_loss: 1.0853 - val_accuracy: 0.4056\n","Epoch 2/3\n","136/136 [==============================] - 1s 7ms/step - loss: 1.0862 - accuracy: 0.4046 - val_loss: 1.0848 - val_accuracy: 0.4056\n","Epoch 3/3\n","136/136 [==============================] - 1s 7ms/step - loss: 1.0855 - accuracy: 0.4046 - val_loss: 1.0841 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 3, batch_size: 256\n","Epoch 1/3\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0901 - accuracy: 0.4046 - val_loss: 1.0867 - val_accuracy: 0.4056\n","Epoch 2/3\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0869 - accuracy: 0.4046 - val_loss: 1.0857 - val_accuracy: 0.4056\n","Epoch 3/3\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0864 - accuracy: 0.4046 - val_loss: 1.0852 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 5, batch_size: 64\n","Epoch 1/5\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0866 - accuracy: 0.4046 - val_loss: 1.0846 - val_accuracy: 0.4056\n","Epoch 2/5\n","272/272 [==============================] - 45s 166ms/step - loss: 1.0850 - accuracy: 0.4046 - val_loss: 1.0834 - val_accuracy: 0.4056\n","Epoch 3/5\n","272/272 [==============================] - 81s 297ms/step - loss: 1.0838 - accuracy: 0.4044 - val_loss: 1.0822 - val_accuracy: 0.4056\n","Epoch 4/5\n","272/272 [==============================] - 79s 289ms/step - loss: 1.0826 - accuracy: 0.4046 - val_loss: 1.0810 - val_accuracy: 0.4057\n","Epoch 5/5\n","272/272 [==============================] - 80s 293ms/step - loss: 1.0814 - accuracy: 0.4050 - val_loss: 1.0799 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 5, batch_size: 128\n","Epoch 1/5\n","136/136 [==============================] - 30s 214ms/step - loss: 1.0902 - accuracy: 0.3933 - val_loss: 1.0856 - val_accuracy: 0.4056\n","Epoch 2/5\n","136/136 [==============================] - 22s 161ms/step - loss: 1.0861 - accuracy: 0.4046 - val_loss: 1.0849 - val_accuracy: 0.4056\n","Epoch 3/5\n","136/136 [==============================] - 1s 9ms/step - loss: 1.0856 - accuracy: 0.4046 - val_loss: 1.0844 - val_accuracy: 0.4056\n","Epoch 4/5\n","136/136 [==============================] - 1s 9ms/step - loss: 1.0849 - accuracy: 0.4046 - val_loss: 1.0838 - val_accuracy: 0.4056\n","Epoch 5/5\n","136/136 [==============================] - 1s 10ms/step - loss: 1.0845 - accuracy: 0.4046 - val_loss: 1.0836 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 5, batch_size: 256\n","Epoch 1/5\n","68/68 [==============================] - 1s 15ms/step - loss: 1.0928 - accuracy: 0.3914 - val_loss: 1.0874 - val_accuracy: 0.4056\n","Epoch 2/5\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0875 - accuracy: 0.4046 - val_loss: 1.0857 - val_accuracy: 0.4056\n","Epoch 3/5\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0867 - accuracy: 0.4046 - val_loss: 1.0853 - val_accuracy: 0.4056\n","Epoch 4/5\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0864 - accuracy: 0.4046 - val_loss: 1.0852 - val_accuracy: 0.4056\n","Epoch 5/5\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0862 - accuracy: 0.4046 - val_loss: 1.0850 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Training model with optimizer: sgd, epochs: 8, batch_size: 64\n","Epoch 1/8\n","272/272 [==============================] - 2s 8ms/step - loss: 1.0877 - accuracy: 0.4021 - val_loss: 1.0856 - val_accuracy: 0.4056\n","Epoch 2/8\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0857 - accuracy: 0.4046 - val_loss: 1.0841 - val_accuracy: 0.4056\n","Epoch 3/8\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0847 - accuracy: 0.4046 - val_loss: 1.0832 - val_accuracy: 0.4056\n","Epoch 4/8\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0834 - accuracy: 0.4045 - val_loss: 1.0824 - val_accuracy: 0.4056\n","Epoch 5/8\n","272/272 [==============================] - 2s 6ms/step - loss: 1.0825 - accuracy: 0.4046 - val_loss: 1.0810 - val_accuracy: 0.4056\n","Epoch 6/8\n","272/272 [==============================] - 7s 24ms/step - loss: 1.0816 - accuracy: 0.4048 - val_loss: 1.0807 - val_accuracy: 0.4057\n","Epoch 7/8\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0806 - accuracy: 0.4057 - val_loss: 1.0815 - val_accuracy: 0.4022\n","Epoch 8/8\n","272/272 [==============================] - 2s 7ms/step - loss: 1.0800 - accuracy: 0.4067 - val_loss: 1.0787 - val_accuracy: 0.4060\n","Validation Accuracy: 0.40432047843933105\n","Training model with optimizer: sgd, epochs: 8, batch_size: 128\n","Epoch 1/8\n","136/136 [==============================] - 4s 26ms/step - loss: 1.0905 - accuracy: 0.3951 - val_loss: 1.0857 - val_accuracy: 0.4056\n","Epoch 2/8\n","136/136 [==============================] - 3s 23ms/step - loss: 1.0862 - accuracy: 0.4046 - val_loss: 1.0847 - val_accuracy: 0.4056\n","Epoch 3/8\n","136/136 [==============================] - 3s 21ms/step - loss: 1.0855 - accuracy: 0.4046 - val_loss: 1.0843 - val_accuracy: 0.4056\n","Epoch 4/8\n","136/136 [==============================] - 2s 14ms/step - loss: 1.0849 - accuracy: 0.4046 - val_loss: 1.0835 - val_accuracy: 0.4056\n","Epoch 5/8\n","136/136 [==============================] - 2s 11ms/step - loss: 1.0843 - accuracy: 0.4046 - val_loss: 1.0833 - val_accuracy: 0.4056\n","Epoch 6/8\n","136/136 [==============================] - 1s 11ms/step - loss: 1.0835 - accuracy: 0.4046 - val_loss: 1.0823 - val_accuracy: 0.4056\n","Epoch 7/8\n","136/136 [==============================] - 3s 19ms/step - loss: 1.0827 - accuracy: 0.4046 - val_loss: 1.0821 - val_accuracy: 0.4056\n","Epoch 8/8\n","136/136 [==============================] - 1s 9ms/step - loss: 1.0820 - accuracy: 0.4049 - val_loss: 1.0811 - val_accuracy: 0.4056\n","Validation Accuracy: 0.40351441502571106\n","Training model with optimizer: sgd, epochs: 8, batch_size: 256\n","Epoch 1/8\n","68/68 [==============================] - 1s 16ms/step - loss: 1.0894 - accuracy: 0.3975 - val_loss: 1.0853 - val_accuracy: 0.4056\n","Epoch 2/8\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0862 - accuracy: 0.4046 - val_loss: 1.0849 - val_accuracy: 0.4056\n","Epoch 3/8\n","68/68 [==============================] - 1s 15ms/step - loss: 1.0858 - accuracy: 0.4046 - val_loss: 1.0844 - val_accuracy: 0.4056\n","Epoch 4/8\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0854 - accuracy: 0.4046 - val_loss: 1.0841 - val_accuracy: 0.4056\n","Epoch 5/8\n","68/68 [==============================] - 1s 12ms/step - loss: 1.0851 - accuracy: 0.4046 - val_loss: 1.0839 - val_accuracy: 0.4056\n","Epoch 6/8\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0848 - accuracy: 0.4046 - val_loss: 1.0837 - val_accuracy: 0.4056\n","Epoch 7/8\n","68/68 [==============================] - 1s 13ms/step - loss: 1.0844 - accuracy: 0.4046 - val_loss: 1.0834 - val_accuracy: 0.4056\n","Epoch 8/8\n","68/68 [==============================] - 1s 14ms/step - loss: 1.0841 - accuracy: 0.4046 - val_loss: 1.0831 - val_accuracy: 0.4056\n","Validation Accuracy: 0.403353214263916\n","Best hyperparameters: {'optimizer': 'rmsprop', 'epochs': 5, 'batch_size': 256}\n","Best validation accuracy: 0.6917620301246643\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","from keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","class CustomTokenizer:\n","    def __init__(self, num_words=None):\n","        self.num_words = num_words\n","        self.word_to_index = {}\n","        self.index_to_word = {}\n","        self.word_counts = {}\n","        self.index = 1  # Start index from 1 (0 reserved for padding)\n","\n","    def fit_on_texts(self, texts):\n","        for text in texts:\n","            for word in text.split():\n","                if word not in self.word_counts:\n","                    self.word_counts[word] = 1\n","                else:\n","                    self.word_counts[word] += 1\n","\n","        # Sort words by frequency and select top num_words if specified\n","        sorted_words = sorted(self.word_counts.items(), key=lambda x: x[1], reverse=True)\n","        if self.num_words:\n","            sorted_words = sorted_words[:self.num_words]\n","\n","        # Assign index to each word\n","        for word, _ in sorted_words:\n","            self.word_to_index[word] = self.index\n","            self.index_to_word[self.index] = word\n","            self.index += 1\n","\n","    def texts_to_sequences(self, texts):\n","        sequences = []\n","        for text in texts:\n","            sequence = [self.word_to_index[word] for word in text.split() if word in self.word_to_index]\n","            sequences.append(sequence)\n","        return sequences\n","\n","\n","\n","# Define a custom preprocessing function\n","def preprocess_text(text):\n","    # Convert text to lowercase\n","    text = text.lower()\n","    # Remove special characters, punctuation, and numbers\n","    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n","    # Tokenize the text\n","    tokens = nltk.word_tokenize(text)\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    # Join tokens back into a string\n","    clean_text = \" \".join(tokens)\n","    return clean_text\n","import pandas as pd\n","\n","df1 = pd.read_csv('train.csv',encoding='latin1')\n","df2 = pd.read_csv('test.csv',encoding='latin1')\n","\n","# Merge the DataFrames\n","twitter_data = pd.concat([df1, df2], ignore_index=True)\n","\n","# Write the merged DataFrame to a new CSV file\n","twitter_data.to_csv('merged_file.csv', index=False)\n","\n","# Drop rows with NaN or null values in the 'text' column\n","twitter_data.dropna(subset=['text'], inplace=True)\n","\n","# Apply the preprocessing function to the 'text' column\n","twitter_data['text'] = twitter_data['text'].apply(preprocess_text)\n","\n","# Create an instance of CustomTokenizer\n","custom_tokenizer = CustomTokenizer(num_words=5000)\n","custom_tokenizer.fit_on_texts(twitter_data['text'])\n","\n","# Convert sentiment labels to numeric form\n","sentiment_mapping = {'neutral': 0, 'positive': 1, 'negative': 2}\n","twitter_data['sentiment_encoded'] = twitter_data['sentiment'].map(sentiment_mapping)\n","\n","# Split the dataset into training and testing sets\n","X = twitter_data['text']\n","y = twitter_data['sentiment_encoded']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert texts to sequences\n","X_train_seq = custom_tokenizer.texts_to_sequences(X_train)\n","X_test_seq = custom_tokenizer.texts_to_sequences(X_test)\n","\n","# Pad sequences to ensure uniform length\n","maxlen = 100\n","X_train_padded = pad_sequences(X_train_seq, maxlen=maxlen)\n","X_test_padded = pad_sequences(X_test_seq, maxlen=maxlen)\n","\n","# Convert labels to categorical format\n","y_train_categorical = to_categorical(y_train)\n","y_test_categorical = to_categorical(y_test)\n","\n","# Define a function to create the model with specified hyperparameters\n","def create_model(optimizer='adam'):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=len(custom_tokenizer.word_to_index) + 1, output_dim=100, input_length=maxlen))\n","    model.add(Flatten())\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(3, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Define the hyperparameters to tune\n","optimizers = ['adam', 'rmsprop', 'sgd']\n","epochs_list = [2,3, 5, 8]\n","batch_sizes = [64, 128, 256]\n","\n","# Perform hyperparameter tuning\n","best_accuracy = 0\n","best_hyperparameters = {}\n","\n","for optimizer in optimizers:\n","    for epochs in epochs_list:\n","        for batch_size in batch_sizes:\n","            print(f\"Training model with optimizer: {optimizer}, epochs: {epochs}, batch_size: {batch_size}\")\n","            \n","            # Create and compile the model with current hyperparameters\n","            model = create_model(optimizer=optimizer)\n","            \n","            # Train the model\n","            history = model.fit(X_train_padded, y_train_categorical, epochs=epochs, batch_size=batch_size, validation_split=0.3, verbose=1)\n","            \n","            # Evaluate the model on validation data\n","            _, accuracy = model.evaluate(X_test_padded, y_test_categorical, verbose=0)\n","            print(f\"Validation Accuracy: {accuracy}\")\n","            \n","            # Update best accuracy and hyperparameters if needed\n","            if accuracy > best_accuracy:\n","                best_accuracy = accuracy\n","                best_hyperparameters = {'optimizer': optimizer, 'epochs': epochs, 'batch_size': batch_size}\n","\n","print(\"Best hyperparameters:\", best_hyperparameters)\n","print(\"Best validation accuracy:\", best_accuracy)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":989445,"sourceId":1808590,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
