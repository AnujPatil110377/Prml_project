{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-19T01:37:34.343690Z","iopub.status.busy":"2024-04-19T01:37:34.343230Z","iopub.status.idle":"2024-04-19T01:37:34.947398Z","shell.execute_reply":"2024-04-19T01:37:34.945434Z","shell.execute_reply.started":"2024-04-19T01:37:34.343658Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","df1 = pd.read_csv('train.csv',encoding='latin1')\n","df2 = pd.read_csv('test.csv',encoding='latin1')\n","\n","# Merge the DataFrames\n","train_data = pd.concat([df1, df2], ignore_index=True)\n","\n","# Write the merged DataFrame to a new CSV file\n","train_data.to_csv('merged_file.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["Removing the Unnecessary columns"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:39.371712Z","iopub.status.busy":"2024-04-19T01:37:39.370463Z","iopub.status.idle":"2024-04-19T01:37:39.382078Z","shell.execute_reply":"2024-04-19T01:37:39.380404Z","shell.execute_reply.started":"2024-04-19T01:37:39.371677Z"},"trusted":true},"outputs":[],"source":["columns_to_remove = ['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n","train_data.drop(columns=columns_to_remove, inplace=True)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:42.065849Z","iopub.status.busy":"2024-04-19T01:37:42.065069Z","iopub.status.idle":"2024-04-19T01:37:42.080171Z","shell.execute_reply":"2024-04-19T01:37:42.079026Z","shell.execute_reply.started":"2024-04-19T01:37:42.065803Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>32291</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32292</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32293</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32294</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32295</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32296 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment\n","0                    I`d have responded, if I were going   neutral\n","1          Sooo SAD I will miss you here in San Diego!!!  negative\n","2                              my boss is bullying me...  negative\n","3                         what interview! leave me alone  negative\n","4       Sons of ****, why couldn`t they put them on t...  negative\n","...                                                  ...       ...\n","32291                                                NaN       NaN\n","32292                                                NaN       NaN\n","32293                                                NaN       NaN\n","32294                                                NaN       NaN\n","32295                                                NaN       NaN\n","\n","[32296 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:45.393561Z","iopub.status.busy":"2024-04-19T01:37:45.393032Z","iopub.status.idle":"2024-04-19T01:37:45.434840Z","shell.execute_reply":"2024-04-19T01:37:45.433152Z","shell.execute_reply.started":"2024-04-19T01:37:45.393509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing Values:\n"," text         1282\n","sentiment    1281\n","dtype: int64\n","\n","Duplicate Rows: 1280\n"]}],"source":["# Check for missing values\n","missing_values = train_data.isnull().sum()\n","print(\"Missing Values:\\n\", missing_values)\n","\n","# Check for duplicates\n","duplicate_rows = train_data.duplicated().sum()\n","print(\"\\nDuplicate Rows:\", duplicate_rows)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:48.121570Z","iopub.status.busy":"2024-04-19T01:37:48.121153Z","iopub.status.idle":"2024-04-19T01:37:48.137707Z","shell.execute_reply":"2024-04-19T01:37:48.135593Z","shell.execute_reply.started":"2024-04-19T01:37:48.121540Z"},"trusted":true},"outputs":[],"source":["train_data.dropna(subset=['text'], inplace=True)\n","# train_data.dropna(subset=['text_lower'],inplace=True)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:37:50.965382Z","iopub.status.busy":"2024-04-19T01:37:50.964966Z","iopub.status.idle":"2024-04-19T01:37:50.983116Z","shell.execute_reply":"2024-04-19T01:37:50.981600Z","shell.execute_reply.started":"2024-04-19T01:37:50.965355Z"},"trusted":true},"outputs":[],"source":["# Lowercase Conversion\n","train_data['text_lower'] = train_data['text'].str.lower()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:01.703114Z","iopub.status.busy":"2024-04-19T01:38:01.702690Z","iopub.status.idle":"2024-04-19T01:38:01.718499Z","shell.execute_reply":"2024-04-19T01:38:01.717036Z","shell.execute_reply.started":"2024-04-19T01:38:01.703084Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>text_lower</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","      <td>i`d have responded, if i were going</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","      <td>sooo sad i will miss you here in san diego!!!</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","      <td>my boss is bullying me...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","      <td>what interview! leave me alone</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","      <td>sons of ****, why couldn`t they put them on t...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","      <td>negative</td>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>All alone in this old house again.  Thanks for...</td>\n","      <td>positive</td>\n","      <td>all alone in this old house again.  thanks for...</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>I know what you mean. My little dog is sinkin...</td>\n","      <td>negative</td>\n","      <td>i know what you mean. my little dog is sinkin...</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","      <td>positive</td>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","      <td>positive</td>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment  \\\n","0                    I`d have responded, if I were going   neutral   \n","1          Sooo SAD I will miss you here in San Diego!!!  negative   \n","2                              my boss is bullying me...  negative   \n","3                         what interview! leave me alone  negative   \n","4       Sons of ****, why couldn`t they put them on t...  negative   \n","...                                                  ...       ...   \n","31010  its at 3 am, im very tired but i can`t sleep  ...  negative   \n","31011  All alone in this old house again.  Thanks for...  positive   \n","31012   I know what you mean. My little dog is sinkin...  negative   \n","31013  _sutra what is your next youtube video gonna b...  positive   \n","31014   http://twitpic.com/4woj2 - omgssh  ang cute n...  positive   \n","\n","                                              text_lower  \n","0                    i`d have responded, if i were going  \n","1          sooo sad i will miss you here in san diego!!!  \n","2                              my boss is bullying me...  \n","3                         what interview! leave me alone  \n","4       sons of ****, why couldn`t they put them on t...  \n","...                                                  ...  \n","31010  its at 3 am, im very tired but i can`t sleep  ...  \n","31011  all alone in this old house again.  thanks for...  \n","31012   i know what you mean. my little dog is sinkin...  \n","31013  _sutra what is your next youtube video gonna b...  \n","31014   http://twitpic.com/4woj2 - omgssh  ang cute n...  \n","\n","[31014 rows x 3 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"markdown","metadata":{},"source":["*****Text cleaning***"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:08.468825Z","iopub.status.busy":"2024-04-19T01:38:08.468377Z","iopub.status.idle":"2024-04-19T01:38:08.794800Z","shell.execute_reply":"2024-04-19T01:38:08.793373Z","shell.execute_reply.started":"2024-04-19T01:38:08.468796Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def clean_text(text):\n","    if isinstance(text, str):  # Check if text is a string\n","        # Remove special characters, HTML tags, and links\n","        cleaned_text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n","        cleaned_text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", cleaned_text)  # Remove links\n","        cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # Remove special characters\n","        return cleaned_text.lower()  # Convert text to lowercase\n","    else:\n","        return text  # Return unchanged if not a string\n","\n","# Apply text cleaning to 'text' column\n","train_data['text'] = train_data['text'].apply(clean_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["**Tokenization: Split the text into individual words or tokens for further analysis.**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:15.427901Z","iopub.status.busy":"2024-04-19T01:38:15.427489Z","iopub.status.idle":"2024-04-19T01:38:15.513084Z","shell.execute_reply":"2024-04-19T01:38:15.511920Z","shell.execute_reply.started":"2024-04-19T01:38:15.427873Z"},"trusted":true},"outputs":[],"source":["def tokenize_text(text):\n","    if isinstance(text, str):\n","        # Split the text into tokens using whitespace as the delimiter\n","        tokens = text.split()\n","        return tokens\n","    else:\n","        return []\n","\n","# Applying the tokenization function to the 'text' column in the train_data DataFrame\n","train_data['tokens'] = train_data['text'].apply(tokenize_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["**Stopwords Removal: Remove common stopwords while preserving the links.**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:22.060730Z","iopub.status.busy":"2024-04-19T01:38:22.060261Z","iopub.status.idle":"2024-04-19T01:38:27.306346Z","shell.execute_reply":"2024-04-19T01:38:27.304969Z","shell.execute_reply.started":"2024-04-19T01:38:22.060699Z"},"trusted":true},"outputs":[],"source":["import requests\n","\n","# Download the stopwords file\n","url = \"https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\"\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Extract stopwords from the content\n","    stopwords = response.text.split(\",\")\n","else:\n","    print(\"Failed to download stopwords file.\")\n","\n","# Stopwords removal function\n","def remove_stopwords(text):\n","    if isinstance(text, str):\n","        # Split the text into tokens using whitespace as delimiter\n","        tokens = text.split()\n","        # Remove stopwords from the tokens\n","        filtered_tokens = [word for word in tokens if word.lower() not in stopwords]\n","        # Join the filtered tokens back into a string\n","        filtered_text = ' '.join(filtered_tokens)\n","        return filtered_text\n","    else:\n","        return text\n","\n","\n","\n","\n","\n","# Applying the stopwords removal function to the 'text' column in the train_data DataFrame\n","train_data['text_without_stopwords'] = train_data['text'].apply(remove_stopwords)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:38:33.731014Z","iopub.status.busy":"2024-04-19T01:38:33.730511Z","iopub.status.idle":"2024-04-19T01:38:33.753932Z","shell.execute_reply":"2024-04-19T01:38:33.753033Z","shell.execute_reply.started":"2024-04-19T01:38:33.730981Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>text_lower</th>\n","      <th>tokens</th>\n","      <th>text_without_stopwords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","      <td>i`d have responded, if i were going</td>\n","      <td>[id, have, responded, if, i, were, going]</td>\n","      <td>responded</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>negative</td>\n","      <td>sooo sad i will miss you here in san diego!!!</td>\n","      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n","      <td>sooo sad san diego</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me</td>\n","      <td>negative</td>\n","      <td>my boss is bullying me...</td>\n","      <td>[my, boss, is, bullying, me]</td>\n","      <td>boss bullying</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview leave me alone</td>\n","      <td>negative</td>\n","      <td>what interview! leave me alone</td>\n","      <td>[what, interview, leave, me, alone]</td>\n","      <td>interview leave</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of  why couldnt they put them on the rel...</td>\n","      <td>negative</td>\n","      <td>sons of ****, why couldn`t they put them on t...</td>\n","      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n","      <td>sons releases bought</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31010</th>\n","      <td>its at 3 am im very tired but i cant sleep  bu...</td>\n","      <td>negative</td>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","      <td>[its, at, 3, am, im, very, tired, but, i, cant...</td>\n","      <td>3 tired sleep</td>\n","    </tr>\n","    <tr>\n","      <th>31011</th>\n","      <td>all alone in this old house again  thanks for ...</td>\n","      <td>positive</td>\n","      <td>all alone in this old house again.  thanks for...</td>\n","      <td>[all, alone, in, this, old, house, again, than...</td>\n","      <td>house net alive kicking invented net wanna kis...</td>\n","    </tr>\n","    <tr>\n","      <th>31012</th>\n","      <td>i know what you mean my little dog is sinking...</td>\n","      <td>negative</td>\n","      <td>i know what you mean. my little dog is sinkin...</td>\n","      <td>[i, know, what, you, mean, my, little, dog, is...</td>\n","      <td>dog sinking depression someplace tropical</td>\n","    </tr>\n","    <tr>\n","      <th>31013</th>\n","      <td>sutra what is your next youtube video gonna be...</td>\n","      <td>positive</td>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","      <td>[sutra, what, is, your, next, youtube, video, ...</td>\n","      <td>sutra youtube video gonna love videos</td>\n","    </tr>\n","    <tr>\n","      <th>31014</th>\n","      <td>omgssh  ang cute ng bby</td>\n","      <td>positive</td>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","      <td>[omgssh, ang, cute, ng, bby]</td>\n","      <td>omgssh ang cute bby</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31014 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                    text sentiment  \\\n","0                      id have responded if i were going   neutral   \n","1             sooo sad i will miss you here in san diego  negative   \n","2                                 my boss is bullying me  negative   \n","3                          what interview leave me alone  negative   \n","4       sons of  why couldnt they put them on the rel...  negative   \n","...                                                  ...       ...   \n","31010  its at 3 am im very tired but i cant sleep  bu...  negative   \n","31011  all alone in this old house again  thanks for ...  positive   \n","31012   i know what you mean my little dog is sinking...  negative   \n","31013  sutra what is your next youtube video gonna be...  positive   \n","31014                            omgssh  ang cute ng bby  positive   \n","\n","                                              text_lower  \\\n","0                    i`d have responded, if i were going   \n","1          sooo sad i will miss you here in san diego!!!   \n","2                              my boss is bullying me...   \n","3                         what interview! leave me alone   \n","4       sons of ****, why couldn`t they put them on t...   \n","...                                                  ...   \n","31010  its at 3 am, im very tired but i can`t sleep  ...   \n","31011  all alone in this old house again.  thanks for...   \n","31012   i know what you mean. my little dog is sinkin...   \n","31013  _sutra what is your next youtube video gonna b...   \n","31014   http://twitpic.com/4woj2 - omgssh  ang cute n...   \n","\n","                                                  tokens  \\\n","0              [id, have, responded, if, i, were, going]   \n","1      [sooo, sad, i, will, miss, you, here, in, san,...   \n","2                           [my, boss, is, bullying, me]   \n","3                    [what, interview, leave, me, alone]   \n","4      [sons, of, why, couldnt, they, put, them, on, ...   \n","...                                                  ...   \n","31010  [its, at, 3, am, im, very, tired, but, i, cant...   \n","31011  [all, alone, in, this, old, house, again, than...   \n","31012  [i, know, what, you, mean, my, little, dog, is...   \n","31013  [sutra, what, is, your, next, youtube, video, ...   \n","31014                       [omgssh, ang, cute, ng, bby]   \n","\n","                                  text_without_stopwords  \n","0                                              responded  \n","1                                     sooo sad san diego  \n","2                                          boss bullying  \n","3                                        interview leave  \n","4                                   sons releases bought  \n","...                                                  ...  \n","31010                                      3 tired sleep  \n","31011  house net alive kicking invented net wanna kis...  \n","31012          dog sinking depression someplace tropical  \n","31013              sutra youtube video gonna love videos  \n","31014                                omgssh ang cute bby  \n","\n","[31014 rows x 5 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:48:34.702502Z","iopub.status.busy":"2024-04-19T01:48:34.700655Z","iopub.status.idle":"2024-04-19T01:48:34.722585Z","shell.execute_reply":"2024-04-19T01:48:34.721428Z","shell.execute_reply.started":"2024-04-19T01:48:34.702432Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Encode the sentiment labels\n","label_encoder = LabelEncoder()\n","train_data['sentiment_encoded'] = label_encoder.fit_transform(train_data['sentiment'])\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T01:51:08.747752Z","iopub.status.busy":"2024-04-19T01:51:08.747284Z","iopub.status.idle":"2024-04-19T01:51:54.927204Z","shell.execute_reply":"2024-04-19T01:51:54.925741Z","shell.execute_reply.started":"2024-04-19T01:51:08.747720Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6595195872964694\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.54      0.62      1749\n","           1       0.58      0.77      0.67      2502\n","           2       0.76      0.62      0.69      1952\n","\n","    accuracy                           0.66      6203\n","   macro avg       0.69      0.64      0.66      6203\n","weighted avg       0.68      0.66      0.66      6203\n","\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Assuming you have already encoded sentiment labels as 'sentiment_encoded'\n","\n","# Step 1: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(train_data['text_without_stopwords'],train_data['sentiment_encoded'], test_size=0.2, random_state=42)\n","\n","# Step 2: Vectorize the text data using TF-IDF\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to top 5000 features\n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)\n","\n","# Step 3: Train the SVM classifier\n","svm_classifier = SVC(kernel='linear')\n","svm_classifier.fit(X_train_tfidf, y_train)\n","\n","# Step 4: Predict sentiment on the test set\n","y_pred = svm_classifier.predict(X_test_tfidf)\n","\n","# Step 5: Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n"]},{"cell_type":"markdown","metadata":{},"source":["**For improving accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T03:54:55.997729Z","iopub.status.busy":"2024-04-19T03:54:55.997130Z","iopub.status.idle":"2024-04-19T04:54:48.186060Z","shell.execute_reply":"2024-04-19T04:54:48.183906Z","shell.execute_reply.started":"2024-04-19T03:54:55.997691Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Parameters: {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n","Accuracy: 0.6595195872964694\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.54      0.62      1749\n","           1       0.58      0.77      0.67      2502\n","           2       0.76      0.62      0.69      1952\n","\n","    accuracy                           0.66      6203\n","   macro avg       0.69      0.64      0.66      6203\n","weighted avg       0.68      0.66      0.66      6203\n","\n"]}],"source":["# Re-split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(train_data['text_without_stopwords'], train_data['sentiment_encoded'], test_size=0.2, random_state=42)\n","\n","# Vectorize the text data using TF-IDF\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)\n","\n","# Tune hyperparameters of the SVM classifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the parameter grid\n","param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'sigmoid']}\n","\n","# Instantiate the GridSearchCV object\n","grid_search = GridSearchCV(SVC(), param_grid, cv=3, n_jobs=-1)\n","\n","# Fit the GridSearchCV object to the training data\n","grid_search.fit(X_train_tfidf, y_train)\n","\n","# Get the best parameters\n","best_params = grid_search.best_params_\n","print(\"Best Parameters:\", best_params)\n","\n","# Use the best parameters to train the SVM classifier\n","best_svm_classifier = SVC(**best_params)\n","best_svm_classifier.fit(X_train_tfidf, y_train)\n","\n","# Predict sentiment on the test set\n","y_pred = best_svm_classifier.predict(X_test_tfidf)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import joblib\n","\n","# Save the SVM classifier model \n","svm_classifier = joblib.dump(svm_classifier, 'Svm.pkl')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":989445,"sourceId":1808590,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
