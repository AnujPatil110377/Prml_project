{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndf1 = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/train.csv',encoding='latin1')\ndf2 = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/test.csv',encoding='latin1')\n\n# Merge the DataFrames\ntrain_data = pd.concat([df1, df2], ignore_index=True)\n\n# Write the merged DataFrame to a new CSV file\ntrain_data.to_csv('merged_file.csv', index=False)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T01:37:34.343230Z","iopub.execute_input":"2024-04-19T01:37:34.343690Z","iopub.status.idle":"2024-04-19T01:37:34.947398Z","shell.execute_reply.started":"2024-04-19T01:37:34.343658Z","shell.execute_reply":"2024-04-19T01:37:34.945434Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Removing the Unnecessary columns","metadata":{}},{"cell_type":"code","source":"columns_to_remove = ['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\ntrain_data.drop(columns=columns_to_remove, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:37:39.370463Z","iopub.execute_input":"2024-04-19T01:37:39.371712Z","iopub.status.idle":"2024-04-19T01:37:39.382078Z","shell.execute_reply.started":"2024-04-19T01:37:39.371677Z","shell.execute_reply":"2024-04-19T01:37:39.380404Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:37:42.065069Z","iopub.execute_input":"2024-04-19T01:37:42.065849Z","iopub.status.idle":"2024-04-19T01:37:42.080171Z","shell.execute_reply.started":"2024-04-19T01:37:42.065803Z","shell.execute_reply":"2024-04-19T01:37:42.079026Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment\n0                    I`d have responded, if I were going   neutral\n1          Sooo SAD I will miss you here in San Diego!!!  negative\n2                              my boss is bullying me...  negative\n3                         what interview! leave me alone  negative\n4       Sons of ****, why couldn`t they put them on t...  negative\n...                                                  ...       ...\n32291                                                NaN       NaN\n32292                                                NaN       NaN\n32293                                                NaN       NaN\n32294                                                NaN       NaN\n32295                                                NaN       NaN\n\n[32296 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32291</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32292</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32293</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32294</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32295</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>32296 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values\nmissing_values = train_data.isnull().sum()\nprint(\"Missing Values:\\n\", missing_values)\n\n# Check for duplicates\nduplicate_rows = train_data.duplicated().sum()\nprint(\"\\nDuplicate Rows:\", duplicate_rows)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:37:45.393032Z","iopub.execute_input":"2024-04-19T01:37:45.393561Z","iopub.status.idle":"2024-04-19T01:37:45.434840Z","shell.execute_reply.started":"2024-04-19T01:37:45.393509Z","shell.execute_reply":"2024-04-19T01:37:45.433152Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Missing Values:\n text         1282\nsentiment    1281\ndtype: int64\n\nDuplicate Rows: 1280\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.dropna(subset=['text'], inplace=True)\n# train_data.dropna(subset=['text_lower'],inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:37:48.121153Z","iopub.execute_input":"2024-04-19T01:37:48.121570Z","iopub.status.idle":"2024-04-19T01:37:48.137707Z","shell.execute_reply.started":"2024-04-19T01:37:48.121540Z","shell.execute_reply":"2024-04-19T01:37:48.135593Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Lowercase Conversion\ntrain_data['text_lower'] = train_data['text'].str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:37:50.964966Z","iopub.execute_input":"2024-04-19T01:37:50.965382Z","iopub.status.idle":"2024-04-19T01:37:50.983116Z","shell.execute_reply.started":"2024-04-19T01:37:50.965355Z","shell.execute_reply":"2024-04-19T01:37:50.981600Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:38:01.702690Z","iopub.execute_input":"2024-04-19T01:38:01.703114Z","iopub.status.idle":"2024-04-19T01:38:01.718499Z","shell.execute_reply.started":"2024-04-19T01:38:01.703084Z","shell.execute_reply":"2024-04-19T01:38:01.717036Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment  \\\n0                    I`d have responded, if I were going   neutral   \n1          Sooo SAD I will miss you here in San Diego!!!  negative   \n2                              my boss is bullying me...  negative   \n3                         what interview! leave me alone  negative   \n4       Sons of ****, why couldn`t they put them on t...  negative   \n...                                                  ...       ...   \n31010  its at 3 am, im very tired but i can`t sleep  ...  negative   \n31011  All alone in this old house again.  Thanks for...  positive   \n31012   I know what you mean. My little dog is sinkin...  negative   \n31013  _sutra what is your next youtube video gonna b...  positive   \n31014   http://twitpic.com/4woj2 - omgssh  ang cute n...  positive   \n\n                                              text_lower  \n0                    i`d have responded, if i were going  \n1          sooo sad i will miss you here in san diego!!!  \n2                              my boss is bullying me...  \n3                         what interview! leave me alone  \n4       sons of ****, why couldn`t they put them on t...  \n...                                                  ...  \n31010  its at 3 am, im very tired but i can`t sleep  ...  \n31011  all alone in this old house again.  thanks for...  \n31012   i know what you mean. my little dog is sinkin...  \n31013  _sutra what is your next youtube video gonna b...  \n31014   http://twitpic.com/4woj2 - omgssh  ang cute n...  \n\n[31014 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>text_lower</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>i`d have responded, if i were going</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>sooo sad i will miss you here in san diego!!!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n      <td>my boss is bullying me...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n      <td>what interview! leave me alone</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n      <td>sons of ****, why couldn`t they put them on t...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31010</th>\n      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n      <td>negative</td>\n      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n    </tr>\n    <tr>\n      <th>31011</th>\n      <td>All alone in this old house again.  Thanks for...</td>\n      <td>positive</td>\n      <td>all alone in this old house again.  thanks for...</td>\n    </tr>\n    <tr>\n      <th>31012</th>\n      <td>I know what you mean. My little dog is sinkin...</td>\n      <td>negative</td>\n      <td>i know what you mean. my little dog is sinkin...</td>\n    </tr>\n    <tr>\n      <th>31013</th>\n      <td>_sutra what is your next youtube video gonna b...</td>\n      <td>positive</td>\n      <td>_sutra what is your next youtube video gonna b...</td>\n    </tr>\n    <tr>\n      <th>31014</th>\n      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n      <td>positive</td>\n      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n    </tr>\n  </tbody>\n</table>\n<p>31014 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"*****Text cleaning***","metadata":{}},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    if isinstance(text, str):  # Check if text is a string\n        # Remove special characters, HTML tags, and links\n        cleaned_text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n        cleaned_text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", cleaned_text)  # Remove links\n        cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # Remove special characters\n        return cleaned_text.lower()  # Convert text to lowercase\n    else:\n        return text  # Return unchanged if not a string\n\n# Apply text cleaning to 'text' column\ntrain_data['text'] = train_data['text'].apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:38:08.468377Z","iopub.execute_input":"2024-04-19T01:38:08.468825Z","iopub.status.idle":"2024-04-19T01:38:08.794800Z","shell.execute_reply.started":"2024-04-19T01:38:08.468796Z","shell.execute_reply":"2024-04-19T01:38:08.793373Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**Tokenization: Split the text into individual words or tokens for further analysis.**","metadata":{}},{"cell_type":"code","source":"def tokenize_text(text):\n    if isinstance(text, str):\n        # Split the text into tokens using whitespace as the delimiter\n        tokens = text.split()\n        return tokens\n    else:\n        return []\n\n# Applying the tokenization function to the 'text' column in the train_data DataFrame\ntrain_data['tokens'] = train_data['text'].apply(tokenize_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:38:15.427489Z","iopub.execute_input":"2024-04-19T01:38:15.427901Z","iopub.status.idle":"2024-04-19T01:38:15.513084Z","shell.execute_reply.started":"2024-04-19T01:38:15.427873Z","shell.execute_reply":"2024-04-19T01:38:15.511920Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"**Stopwords Removal: Remove common stopwords while preserving the links.**","metadata":{}},{"cell_type":"code","source":"import requests\n\n# Download the stopwords file\nurl = \"https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\"\nresponse = requests.get(url)\n\n# Check if the request was successful\nif response.status_code == 200:\n    # Extract stopwords from the content\n    stopwords = response.text.split(\",\")\nelse:\n    print(\"Failed to download stopwords file.\")\n\n# Stopwords removal function\ndef remove_stopwords(text):\n    if isinstance(text, str):\n        # Split the text into tokens using whitespace as delimiter\n        tokens = text.split()\n        # Remove stopwords from the tokens\n        filtered_tokens = [word for word in tokens if word.lower() not in stopwords]\n        # Join the filtered tokens back into a string\n        filtered_text = ' '.join(filtered_tokens)\n        return filtered_text\n    else:\n        return text\n\n\n\n\n\n# Applying the stopwords removal function to the 'text' column in the train_data DataFrame\ntrain_data['text_without_stopwords'] = train_data['text'].apply(remove_stopwords)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:38:22.060261Z","iopub.execute_input":"2024-04-19T01:38:22.060730Z","iopub.status.idle":"2024-04-19T01:38:27.306346Z","shell.execute_reply.started":"2024-04-19T01:38:22.060699Z","shell.execute_reply":"2024-04-19T01:38:27.304969Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:38:33.730511Z","iopub.execute_input":"2024-04-19T01:38:33.731014Z","iopub.status.idle":"2024-04-19T01:38:33.753932Z","shell.execute_reply.started":"2024-04-19T01:38:33.730981Z","shell.execute_reply":"2024-04-19T01:38:33.753033Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment  \\\n0                      id have responded if i were going   neutral   \n1             sooo sad i will miss you here in san diego  negative   \n2                                 my boss is bullying me  negative   \n3                          what interview leave me alone  negative   \n4       sons of  why couldnt they put them on the rel...  negative   \n...                                                  ...       ...   \n31010  its at 3 am im very tired but i cant sleep  bu...  negative   \n31011  all alone in this old house again  thanks for ...  positive   \n31012   i know what you mean my little dog is sinking...  negative   \n31013  sutra what is your next youtube video gonna be...  positive   \n31014                            omgssh  ang cute ng bby  positive   \n\n                                              text_lower  \\\n0                    i`d have responded, if i were going   \n1          sooo sad i will miss you here in san diego!!!   \n2                              my boss is bullying me...   \n3                         what interview! leave me alone   \n4       sons of ****, why couldn`t they put them on t...   \n...                                                  ...   \n31010  its at 3 am, im very tired but i can`t sleep  ...   \n31011  all alone in this old house again.  thanks for...   \n31012   i know what you mean. my little dog is sinkin...   \n31013  _sutra what is your next youtube video gonna b...   \n31014   http://twitpic.com/4woj2 - omgssh  ang cute n...   \n\n                                                  tokens  \\\n0              [id, have, responded, if, i, were, going]   \n1      [sooo, sad, i, will, miss, you, here, in, san,...   \n2                           [my, boss, is, bullying, me]   \n3                    [what, interview, leave, me, alone]   \n4      [sons, of, why, couldnt, they, put, them, on, ...   \n...                                                  ...   \n31010  [its, at, 3, am, im, very, tired, but, i, cant...   \n31011  [all, alone, in, this, old, house, again, than...   \n31012  [i, know, what, you, mean, my, little, dog, is...   \n31013  [sutra, what, is, your, next, youtube, video, ...   \n31014                       [omgssh, ang, cute, ng, bby]   \n\n                                  text_without_stopwords  \n0                                              responded  \n1                                     sooo sad san diego  \n2                                          boss bullying  \n3                                        interview leave  \n4                                   sons releases bought  \n...                                                  ...  \n31010                                      3 tired sleep  \n31011  house net alive kicking invented net wanna kis...  \n31012          dog sinking depression someplace tropical  \n31013              sutra youtube video gonna love videos  \n31014                                omgssh ang cute bby  \n\n[31014 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>text_lower</th>\n      <th>tokens</th>\n      <th>text_without_stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id have responded if i were going</td>\n      <td>neutral</td>\n      <td>i`d have responded, if i were going</td>\n      <td>[id, have, responded, if, i, were, going]</td>\n      <td>responded</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sooo sad i will miss you here in san diego</td>\n      <td>negative</td>\n      <td>sooo sad i will miss you here in san diego!!!</td>\n      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n      <td>sooo sad san diego</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me</td>\n      <td>negative</td>\n      <td>my boss is bullying me...</td>\n      <td>[my, boss, is, bullying, me]</td>\n      <td>boss bullying</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview leave me alone</td>\n      <td>negative</td>\n      <td>what interview! leave me alone</td>\n      <td>[what, interview, leave, me, alone]</td>\n      <td>interview leave</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sons of  why couldnt they put them on the rel...</td>\n      <td>negative</td>\n      <td>sons of ****, why couldn`t they put them on t...</td>\n      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n      <td>sons releases bought</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31010</th>\n      <td>its at 3 am im very tired but i cant sleep  bu...</td>\n      <td>negative</td>\n      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n      <td>[its, at, 3, am, im, very, tired, but, i, cant...</td>\n      <td>3 tired sleep</td>\n    </tr>\n    <tr>\n      <th>31011</th>\n      <td>all alone in this old house again  thanks for ...</td>\n      <td>positive</td>\n      <td>all alone in this old house again.  thanks for...</td>\n      <td>[all, alone, in, this, old, house, again, than...</td>\n      <td>house net alive kicking invented net wanna kis...</td>\n    </tr>\n    <tr>\n      <th>31012</th>\n      <td>i know what you mean my little dog is sinking...</td>\n      <td>negative</td>\n      <td>i know what you mean. my little dog is sinkin...</td>\n      <td>[i, know, what, you, mean, my, little, dog, is...</td>\n      <td>dog sinking depression someplace tropical</td>\n    </tr>\n    <tr>\n      <th>31013</th>\n      <td>sutra what is your next youtube video gonna be...</td>\n      <td>positive</td>\n      <td>_sutra what is your next youtube video gonna b...</td>\n      <td>[sutra, what, is, your, next, youtube, video, ...</td>\n      <td>sutra youtube video gonna love videos</td>\n    </tr>\n    <tr>\n      <th>31014</th>\n      <td>omgssh  ang cute ng bby</td>\n      <td>positive</td>\n      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n      <td>[omgssh, ang, cute, ng, bby]</td>\n      <td>omgssh ang cute bby</td>\n    </tr>\n  </tbody>\n</table>\n<p>31014 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Encode the sentiment labels\nlabel_encoder = LabelEncoder()\ntrain_data['sentiment_encoded'] = label_encoder.fit_transform(train_data['sentiment'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:48:34.700655Z","iopub.execute_input":"2024-04-19T01:48:34.702502Z","iopub.status.idle":"2024-04-19T01:48:34.722585Z","shell.execute_reply.started":"2024-04-19T01:48:34.702432Z","shell.execute_reply":"2024-04-19T01:48:34.721428Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Assuming you have already encoded sentiment labels as 'sentiment_encoded'\n\n# Step 1: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(train_data['text_without_stopwords'],train_data['sentiment_encoded'], test_size=0.2, random_state=42)\n\n# Step 2: Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to top 5000 features\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)\n\n# Step 3: Train the SVM classifier\nsvm_classifier = SVC(kernel='linear')\nsvm_classifier.fit(X_train_tfidf, y_train)\n\n# Step 4: Predict sentiment on the test set\ny_pred = svm_classifier.predict(X_test_tfidf)\n\n# Step 5: Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T01:51:08.747284Z","iopub.execute_input":"2024-04-19T01:51:08.747752Z","iopub.status.idle":"2024-04-19T01:51:54.927204Z","shell.execute_reply.started":"2024-04-19T01:51:08.747720Z","shell.execute_reply":"2024-04-19T01:51:54.925741Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Accuracy: 0.6595195872964694\n              precision    recall  f1-score   support\n\n           0       0.72      0.54      0.62      1749\n           1       0.58      0.77      0.67      2502\n           2       0.76      0.62      0.69      1952\n\n    accuracy                           0.66      6203\n   macro avg       0.69      0.64      0.66      6203\nweighted avg       0.68      0.66      0.66      6203\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**For improving accuracy**","metadata":{}},{"cell_type":"code","source":"# Re-split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(train_data['text_without_stopwords'], train_data['sentiment_encoded'], test_size=0.2, random_state=42)\n\n# Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)\n\n# Tune hyperparameters of the SVM classifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid\nparam_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'sigmoid']}\n\n# Instantiate the GridSearchCV object\ngrid_search = GridSearchCV(SVC(), param_grid, cv=3, n_jobs=-1)\n\n# Fit the GridSearchCV object to the training data\ngrid_search.fit(X_train_tfidf, y_train)\n\n# Get the best parameters\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n\n# Use the best parameters to train the SVM classifier\nbest_svm_classifier = SVC(**best_params)\nbest_svm_classifier.fit(X_train_tfidf, y_train)\n\n# Predict sentiment on the test set\ny_pred = best_svm_classifier.predict(X_test_tfidf)\n\n# Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T03:54:55.997130Z","iopub.execute_input":"2024-04-19T03:54:55.997729Z","iopub.status.idle":"2024-04-19T04:54:48.186060Z","shell.execute_reply.started":"2024-04-19T03:54:55.997691Z","shell.execute_reply":"2024-04-19T04:54:48.183906Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Best Parameters: {'C': 1, 'gamma': 1, 'kernel': 'linear'}\nAccuracy: 0.6595195872964694\n              precision    recall  f1-score   support\n\n           0       0.72      0.54      0.62      1749\n           1       0.58      0.77      0.67      2502\n           2       0.76      0.62      0.69      1952\n\n    accuracy                           0.66      6203\n   macro avg       0.69      0.64      0.66      6203\nweighted avg       0.68      0.66      0.66      6203\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}