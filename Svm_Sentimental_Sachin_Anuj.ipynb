{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ntrain_data=pd.read_csv('/kaggle/input/sentiment-analysis-dataset/train.csv',encoding='latin1')\ntrain_data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T22:06:17.137027Z","iopub.execute_input":"2024-04-18T22:06:17.137454Z","iopub.status.idle":"2024-04-18T22:06:17.297680Z","shell.execute_reply.started":"2024-04-18T22:06:17.137420Z","shell.execute_reply":"2024-04-18T22:06:17.296786Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"           textID                                               text  \\\n0      cb774db0d1                I`d have responded, if I were going   \n1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2      088c60f138                          my boss is bullying me...   \n3      9642c003ef                     what interview! leave me alone   \n4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n...           ...                                                ...   \n27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n27479  ed167662a5                         But it was worth it  ****.   \n27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n\n                                           selected_text sentiment  \\\n0                    I`d have responded, if I were going   neutral   \n1                                               Sooo SAD  negative   \n2                                            bullying me  negative   \n3                                         leave me alone  negative   \n4                                          Sons of ****,  negative   \n...                                                  ...       ...   \n27476                                             d lost  negative   \n27477                                      , don`t force  negative   \n27478                          Yay good for both of you.  positive   \n27479                         But it was worth it  ****.  positive   \n27480  All this flirting going on - The ATG smiles. Y...   neutral   \n\n      Time of Tweet Age of User      Country  Population -2020  \\\n0           morning        0-20  Afghanistan          38928346   \n1              noon       21-30      Albania           2877797   \n2             night       31-45      Algeria          43851044   \n3           morning       46-60      Andorra             77265   \n4              noon       60-70       Angola          32866272   \n...             ...         ...          ...               ...   \n27476         night       31-45        Ghana          31072940   \n27477       morning       46-60       Greece          10423054   \n27478          noon       60-70      Grenada            112523   \n27479         night      70-100    Guatemala          17915568   \n27480       morning        0-20       Guinea          13132795   \n\n       Land Area (Km²)  Density (P/Km²)  \n0             652860.0               60  \n1              27400.0              105  \n2            2381740.0               18  \n3                470.0              164  \n4            1246700.0               26  \n...                ...              ...  \n27476         227540.0              137  \n27477         128900.0               81  \n27478            340.0              331  \n27479         107160.0              167  \n27480         246000.0               53  \n\n[27481 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272</td>\n      <td>1246700.0</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>4eac33d1c0</td>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>d lost</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Ghana</td>\n      <td>31072940</td>\n      <td>227540.0</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>4f4c4fc327</td>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>, don`t force</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Greece</td>\n      <td>10423054</td>\n      <td>128900.0</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>f67aae2310</td>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>Yay good for both of you.</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Grenada</td>\n      <td>112523</td>\n      <td>340.0</td>\n      <td>331</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>ed167662a5</td>\n      <td>But it was worth it  ****.</td>\n      <td>But it was worth it  ****.</td>\n      <td>positive</td>\n      <td>night</td>\n      <td>70-100</td>\n      <td>Guatemala</td>\n      <td>17915568</td>\n      <td>107160.0</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>6f7127d9d7</td>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>All this flirting going on - The ATG smiles. Y...</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Guinea</td>\n      <td>13132795</td>\n      <td>246000.0</td>\n      <td>53</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Removing the Unnecessary columns","metadata":{}},{"cell_type":"code","source":"columns_to_remove = ['textID', 'selected_text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\ntrain_data.drop(columns=columns_to_remove, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:06:21.132473Z","iopub.execute_input":"2024-04-18T22:06:21.132915Z","iopub.status.idle":"2024-04-18T22:06:21.145994Z","shell.execute_reply.started":"2024-04-18T22:06:21.132873Z","shell.execute_reply":"2024-04-18T22:06:21.144715Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:06:49.100633Z","iopub.execute_input":"2024-04-18T22:06:49.101047Z","iopub.status.idle":"2024-04-18T22:06:49.115685Z","shell.execute_reply.started":"2024-04-18T22:06:49.101016Z","shell.execute_reply":"2024-04-18T22:06:49.114362Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment\n0                    I`d have responded, if I were going   neutral\n1          Sooo SAD I will miss you here in San Diego!!!  negative\n2                              my boss is bullying me...  negative\n3                         what interview! leave me alone  negative\n4       Sons of ****, why couldn`t they put them on t...  negative\n...                                                  ...       ...\n27476   wish we could come see u on Denver  husband l...  negative\n27477   I`ve wondered about rake to.  The client has ...  negative\n27478   Yay good for both of you. Enjoy the break - y...  positive\n27479                         But it was worth it  ****.  positive\n27480     All this flirting going on - The ATG smiles...   neutral\n\n[27481 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>But it was worth it  ****.</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Check for missing value**","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing_values = train_data.isnull().sum()\nprint(\"Missing Values:\\n\", missing_values)\n\n# Check for duplicates\nduplicate_rows = train_data.duplicated().sum()\nprint(\"\\nDuplicate Rows:\", duplicate_rows)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:08:05.478784Z","iopub.execute_input":"2024-04-18T22:08:05.479224Z","iopub.status.idle":"2024-04-18T22:08:05.515627Z","shell.execute_reply.started":"2024-04-18T22:08:05.479188Z","shell.execute_reply":"2024-04-18T22:08:05.514454Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Missing Values:\n text         1\nsentiment    0\ndtype: int64\n\nDuplicate Rows: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**since we have a rows which contains text column missing so we will remove it**","metadata":{}},{"cell_type":"code","source":"train_data.dropna(subset=['text'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:08:32.241293Z","iopub.execute_input":"2024-04-18T22:08:32.242612Z","iopub.status.idle":"2024-04-18T22:08:32.255674Z","shell.execute_reply.started":"2024-04-18T22:08:32.242569Z","shell.execute_reply":"2024-04-18T22:08:32.254280Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"*****Text cleaning***","metadata":{}},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    if isinstance(text, str):  # Check if text is a string\n        # Remove special characters and HTML tags (except for links)\n        cleaned_text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n        cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # Remove special characters\n        return cleaned_text.lower()  # Convert text to lowercase\n    else:\n        return text  # Return unchanged if not a string\n\n# Apply text cleaning to 'text' column\ntrain_data['text'] = train_data['text'].apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:09:18.254871Z","iopub.execute_input":"2024-04-18T22:09:18.255351Z","iopub.status.idle":"2024-04-18T22:09:18.455758Z","shell.execute_reply.started":"2024-04-18T22:09:18.255317Z","shell.execute_reply":"2024-04-18T22:09:18.454443Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Tokenization: Split the text into individual words or tokens for further analysis.**","metadata":{}},{"cell_type":"code","source":"def tokenize_text(text):\n    if isinstance(text, str):\n        # Split the text into tokens using whitespace as the delimiter\n        tokens = text.split()\n        return tokens\n    else:\n        return []\n\n# Applying the tokenization function to the 'text' column in the train_data DataFrame\ntrain_data['tokens'] = train_data['text'].apply(tokenize_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:13:58.823893Z","iopub.execute_input":"2024-04-18T22:13:58.824329Z","iopub.status.idle":"2024-04-18T22:13:59.010667Z","shell.execute_reply.started":"2024-04-18T22:13:58.824300Z","shell.execute_reply":"2024-04-18T22:13:59.009077Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Stopwords Removal: Remove common stopwords while preserving the links.**","metadata":{}},{"cell_type":"code","source":"import requests\n\n# Download the stopwords file\nurl = \"https://gist.githubusercontent.com/ZohebAbai/513218c3468130eacff6481f424e4e64/raw/b70776f341a148293ff277afa0d0302c8c38f7e2/gist_stopwords.txt\"\nresponse = requests.get(url)\n\n# Check if the request was successful\nif response.status_code == 200:\n    # Extract stopwords from the content\n    stopwords = response.text.split(\",\")\nelse:\n    print(\"Failed to download stopwords file.\")\n\n# Stopwords removal function\ndef remove_stopwords(text):\n    if isinstance(text, str):\n        # Split the text into tokens using whitespace as delimiter\n        tokens = text.split()\n        # Remove stopwords from the tokens\n        filtered_tokens = [word for word in tokens if word.lower() not in stopwords]\n        # Join the filtered tokens back into a string\n        filtered_text = ' '.join(filtered_tokens)\n        return filtered_text\n    else:\n        return text\n\n\n\n\n\n# Applying the stopwords removal function to the 'text' column in the train_data DataFrame\ntrain_data['text_without_stopwords'] = train_data['text'].apply(remove_stopwords)\nprint(train_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:39:41.907399Z","iopub.execute_input":"2024-04-18T22:39:41.907814Z","iopub.status.idle":"2024-04-18T22:39:46.850688Z","shell.execute_reply.started":"2024-04-18T22:39:41.907784Z","shell.execute_reply":"2024-04-18T22:39:46.849302Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"                                                text sentiment  \\\n0                  id have responded if i were going   neutral   \n1         sooo sad i will miss you here in san diego  negative   \n2                             my boss is bullying me  negative   \n3                      what interview leave me alone  negative   \n4   sons of  why couldnt they put them on the rel...  negative   \n\n                                              tokens text_without_stopwords  \\\n0          [id, have, responded, if, i, were, going]              responded   \n1  [sooo, sad, i, will, miss, you, here, in, san,...     sooo sad san diego   \n2                       [my, boss, is, bullying, me]          boss bullying   \n3                [what, interview, leave, me, alone]        interview leave   \n4  [sons, of, why, couldnt, they, put, them, on, ...   sons releases bought   \n\n                                       text_features  word_count  char_count  \\\n0  {'word_count': 7, 'char_count': 34, 'has_links...         7.0        34.0   \n1  {'word_count': 10, 'char_count': 43, 'has_link...        10.0        43.0   \n2  {'word_count': 5, 'char_count': 22, 'has_links...         5.0        22.0   \n3  {'word_count': 5, 'char_count': 30, 'has_links...         5.0        30.0   \n4  {'word_count': 13, 'char_count': 69, 'has_link...        13.0        69.0   \n\n   has_links  word_count  char_count  has_links  \n0        0.0         7.0        34.0        0.0  \n1        0.0        10.0        43.0        0.0  \n2        0.0         5.0        22.0        0.0  \n3        0.0         5.0        30.0        0.0  \n4        0.0        13.0        69.0        0.0  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Stemming or Lemmatization: Reduce words to their base or root form.**","metadata":{}},{"cell_type":"code","source":"def stem_word(word):\n    # Define stemming rules\n    suffixes = {\n        's': '',       # Remove plural 's'\n        'es': '',      # Remove plural 'es'\n        'ies': 'y',    # Replace 'ies' with 'y'\n        'ed': '',      # Remove past tense 'ed'\n        'ing': '',     # Remove present participle 'ing'\n        'ly': '',      # Remove adverb suffix 'ly'\n        'er': '',      # Remove comparative suffix 'er'\n        'est': '',     # Remove superlative suffix 'est'\n        'y': 'i',      # Replace 'y' with 'i' if preceded by a consonant\n        'ation': 'ate',  # Replace 'ation' with 'ate'\n        'tion': 'te',    # Replace 'tion' with 'te'\n        'er': '',        # Remove comparative suffix 'er'\n        'est': '',       # Remove superlative suffix 'est'\n        'ment': '',      # Remove suffix 'ment'\n        'ness': '',      # Remove suffix 'ness'\n        'ive': '',       # Remove suffix 'ive'\n        'ful': '',       # Remove suffix 'ful'\n        'ness': '',      # Remove suffix 'ness'\n        'less': '',      # Remove suffix 'less'\n        # Add more stemming rules as needed\n    }\n    \n    for suffix in suffixes:\n        if word.endswith(suffix):\n            # Apply the stemming rule by removing the suffix or replacing characters\n            if suffix == 'y' and len(word) > 1 and word[-2] not in 'aeiou':\n                return word[:-len(suffix)] + suffixes[suffix]\n            else:\n                return word[:-len(suffix)] + suffixes[suffix]\n    \n    return word  # Return the word unchanged if no stemming rule applies\n\n# Example usage\nword = \"running\"\nstemmed_word = stem_word(word)\nprint(\"Original Word:\", word)\nprint(\"Stemmed Word:\", stemmed_word)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:40:49.124709Z","iopub.execute_input":"2024-04-18T22:40:49.125141Z","iopub.status.idle":"2024-04-18T22:40:50.516642Z","shell.execute_reply.started":"2024-04-18T22:40:49.125108Z","shell.execute_reply":"2024-04-18T22:40:50.514441Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Failed to download stemming rules file.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(suffix)] \u001b[38;5;241m+\u001b[39m suffixes[suffix]\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word  \u001b[38;5;66;03m# Return the word unchanged if no stemming rule applies\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_after_removing_stemword\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_without_stopwords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem_word\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[22], line 20\u001b[0m, in \u001b[0;36mstem_word\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstem_word\u001b[39m(word):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m \u001b[43msuffixes\u001b[49m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mendswith(suffix):\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;66;03m# Apply the stemming rule by removing the suffix or replacing characters\u001b[39;00m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m word[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maeiou\u001b[39m\u001b[38;5;124m'\u001b[39m:\n","\u001b[0;31mNameError\u001b[0m: name 'suffixes' is not defined"],"ename":"NameError","evalue":"name 'suffixes' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import re\n\n# Feature Engineering\ndef extract_features(text):\n    features = {}\n\n    if isinstance(text, str):  # Check if text is a string\n        # Word count\n        words = text.split()  # Split text into words\n        features['word_count'] = len(words)\n\n        # Character count\n        features['char_count'] = len(text)\n\n        # Presence of links\n        features['has_links'] = 1 if re.search(r\"http\\S+|www\\S+\", text) else 0\n\n    else:\n        # Set features to None for non-string inputs\n        features['word_count'] = None\n        features['char_count'] = None\n        features['has_links'] = None\n\n    return features\n\n# Apply feature extraction to 'text' column\ntrain_data['text_features'] = train_data['text'].apply(extract_features)\n\n# Convert the extracted features into DataFrame columns\ndf_features = pd.DataFrame(train_data['text_features'].tolist())\n\n# Concatenate the extracted features DataFrame with the original DataFrame\ntrain_data = pd.concat([train_data, df_features], axis=1)\n\n\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:30:21.865924Z","iopub.execute_input":"2024-04-18T22:30:21.866345Z","iopub.status.idle":"2024-04-18T22:30:22.137432Z","shell.execute_reply.started":"2024-04-18T22:30:21.866312Z","shell.execute_reply":"2024-04-18T22:30:22.136152Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment  \\\n0                      id have responded if i were going   neutral   \n1             sooo sad i will miss you here in san diego  negative   \n2                                 my boss is bullying me  negative   \n3                          what interview leave me alone  negative   \n4       sons of  why couldnt they put them on the rel...  negative   \n...                                                  ...       ...   \n27477   ive wondered about rake to  the client has ma...  negative   \n27478   yay good for both of you enjoy the break  you...  positive   \n27479                              but it was worth it    positive   \n27480     all this flirting going on  the atg smiles ...   neutral   \n314                                                  NaN       NaN   \n\n                                                  tokens  \\\n0              [id, have, responded, if, i, were, going]   \n1      [sooo, sad, i, will, miss, you, here, in, san,...   \n2                           [my, boss, is, bullying, me]   \n3                    [what, interview, leave, me, alone]   \n4      [sons, of, why, couldnt, they, put, them, on, ...   \n...                                                  ...   \n27477  [ive, wondered, about, rake, to, the, client, ...   \n27478  [yay, good, for, both, of, you, enjoy, the, br...   \n27479                          [but, it, was, worth, it]   \n27480  [all, this, flirting, going, on, the, atg, smi...   \n314                                                  NaN   \n\n                                  text_without_stopwords  \\\n0                                              responded   \n1                                     sooo sad san diego   \n2                                          boss bullying   \n3                                        interview leave   \n4                                   sons releases bought   \n...                                                  ...   \n27477  ive wondered rake client clear net dont force ...   \n27478  yay good enjoy break hectic weekend care hun xxxx   \n27479                                              worth   \n27480                       flirting atg smiles yay hugs   \n314                                                  NaN   \n\n                                           text_features  word_count  \\\n0      {'word_count': 7, 'char_count': 34, 'has_links...         7.0   \n1      {'word_count': 10, 'char_count': 43, 'has_link...        10.0   \n2      {'word_count': 5, 'char_count': 22, 'has_links...         5.0   \n3      {'word_count': 5, 'char_count': 30, 'has_links...         5.0   \n4      {'word_count': 13, 'char_count': 69, 'has_link...        13.0   \n...                                                  ...         ...   \n27477  {'word_count': 23, 'char_count': 115, 'has_lin...        21.0   \n27478  {'word_count': 21, 'char_count': 109, 'has_lin...         5.0   \n27479  {'word_count': 5, 'char_count': 22, 'has_links...        10.0   \n27480  {'word_count': 10, 'char_count': 55, 'has_link...         NaN   \n314    {'word_count': None, 'char_count': None, 'has_...        24.0   \n\n       char_count  has_links  word_count  char_count  has_links  \n0            34.0        0.0         7.0        34.0        0.0  \n1            43.0        0.0        10.0        43.0        0.0  \n2            22.0        0.0         5.0        22.0        0.0  \n3            30.0        0.0         5.0        30.0        0.0  \n4            69.0        0.0        13.0        69.0        0.0  \n...           ...        ...         ...         ...        ...  \n27477       109.0        0.0        21.0       109.0        0.0  \n27478        22.0        0.0         5.0        22.0        0.0  \n27479        55.0        0.0        10.0        55.0        0.0  \n27480         NaN        NaN         NaN         NaN        NaN  \n314         125.0        0.0        24.0       125.0        0.0  \n\n[27481 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>text_without_stopwords</th>\n      <th>text_features</th>\n      <th>word_count</th>\n      <th>char_count</th>\n      <th>has_links</th>\n      <th>word_count</th>\n      <th>char_count</th>\n      <th>has_links</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id have responded if i were going</td>\n      <td>neutral</td>\n      <td>[id, have, responded, if, i, were, going]</td>\n      <td>responded</td>\n      <td>{'word_count': 7, 'char_count': 34, 'has_links...</td>\n      <td>7.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sooo sad i will miss you here in san diego</td>\n      <td>negative</td>\n      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n      <td>sooo sad san diego</td>\n      <td>{'word_count': 10, 'char_count': 43, 'has_link...</td>\n      <td>10.0</td>\n      <td>43.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>43.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me</td>\n      <td>negative</td>\n      <td>[my, boss, is, bullying, me]</td>\n      <td>boss bullying</td>\n      <td>{'word_count': 5, 'char_count': 22, 'has_links...</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview leave me alone</td>\n      <td>negative</td>\n      <td>[what, interview, leave, me, alone]</td>\n      <td>interview leave</td>\n      <td>{'word_count': 5, 'char_count': 30, 'has_links...</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sons of  why couldnt they put them on the rel...</td>\n      <td>negative</td>\n      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n      <td>sons releases bought</td>\n      <td>{'word_count': 13, 'char_count': 69, 'has_link...</td>\n      <td>13.0</td>\n      <td>69.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>69.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>ive wondered about rake to  the client has ma...</td>\n      <td>negative</td>\n      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n      <td>ive wondered rake client clear net dont force ...</td>\n      <td>{'word_count': 23, 'char_count': 115, 'has_lin...</td>\n      <td>21.0</td>\n      <td>109.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>109.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>yay good for both of you enjoy the break  you...</td>\n      <td>positive</td>\n      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n      <td>yay good enjoy break hectic weekend care hun xxxx</td>\n      <td>{'word_count': 21, 'char_count': 109, 'has_lin...</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>but it was worth it</td>\n      <td>positive</td>\n      <td>[but, it, was, worth, it]</td>\n      <td>worth</td>\n      <td>{'word_count': 5, 'char_count': 22, 'has_links...</td>\n      <td>10.0</td>\n      <td>55.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>55.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>all this flirting going on  the atg smiles ...</td>\n      <td>neutral</td>\n      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n      <td>flirting atg smiles yay hugs</td>\n      <td>{'word_count': 10, 'char_count': 55, 'has_link...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>314</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'word_count': None, 'char_count': None, 'has_...</td>\n      <td>24.0</td>\n      <td>125.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>125.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**We have done this because we don't know why 27480 row number contain NaN althought it contains words**","metadata":{}},{"cell_type":"code","source":"train_data[\"word_count\"][27480]= 10\ntrain_data[\"char_count\"][27480]= 55\ntrain_data[\"has_links\"][27480]= 0.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-04-18T22:21:23.588470Z","iopub.execute_input":"2024-04-18T22:21:23.588927Z","iopub.status.idle":"2024-04-18T22:21:23.618867Z","shell.execute_reply.started":"2024-04-18T22:21:23.588890Z","shell.execute_reply":"2024-04-18T22:21:23.617693Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment  \\\n0                      id have responded if i were going   neutral   \n1             sooo sad i will miss you here in san diego  negative   \n2                                 my boss is bullying me  negative   \n3                          what interview leave me alone  negative   \n4       sons of  why couldnt they put them on the rel...  negative   \n...                                                  ...       ...   \n27477   ive wondered about rake to  the client has ma...  negative   \n27478   yay good for both of you enjoy the break  you...  positive   \n27479                              but it was worth it    positive   \n27480     all this flirting going on  the atg smiles ...   neutral   \n314                                                  NaN       NaN   \n\n                                                  tokens  \\\n0              [id, have, responded, if, i, were, going]   \n1      [sooo, sad, i, will, miss, you, here, in, san,...   \n2                           [my, boss, is, bullying, me]   \n3                    [what, interview, leave, me, alone]   \n4      [sons, of, why, couldnt, they, put, them, on, ...   \n...                                                  ...   \n27477  [ive, wondered, about, rake, to, the, client, ...   \n27478  [yay, good, for, both, of, you, enjoy, the, br...   \n27479                          [but, it, was, worth, it]   \n27480  [all, this, flirting, going, on, the, atg, smi...   \n314                                                  NaN   \n\n                                  text_without_stopwords  \\\n0                                     id responded going   \n1                                sooo sad miss san diego   \n2                                          boss bullying   \n3                                  interview leave alone   \n4               sons couldnt put releases already bought   \n...                                                  ...   \n27477  ive wondered rake client made clear net dont f...   \n27478  yay good enjoy break probably need hectic week...   \n27479                                              worth   \n27480                 flirting going atg smiles yay hugs   \n314                                                  NaN   \n\n                                           text_features  word_count  \\\n0      {'word_count': 7, 'char_count': 34, 'has_links...         7.0   \n1      {'word_count': 10, 'char_count': 43, 'has_link...        10.0   \n2      {'word_count': 5, 'char_count': 22, 'has_links...         5.0   \n3      {'word_count': 5, 'char_count': 30, 'has_links...         5.0   \n4      {'word_count': 13, 'char_count': 69, 'has_link...        13.0   \n...                                                  ...         ...   \n27477  {'word_count': 23, 'char_count': 115, 'has_lin...        21.0   \n27478  {'word_count': 21, 'char_count': 109, 'has_lin...         5.0   \n27479  {'word_count': 5, 'char_count': 22, 'has_links...        10.0   \n27480  {'word_count': 10, 'char_count': 55, 'has_link...         NaN   \n314                                                  NaN        24.0   \n\n       char_count  has_links  \n0            34.0        0.0  \n1            43.0        0.0  \n2            22.0        0.0  \n3            30.0        0.0  \n4            69.0        0.0  \n...           ...        ...  \n27477       109.0        0.0  \n27478        22.0        0.0  \n27479        55.0        0.0  \n27480         NaN        NaN  \n314         125.0        0.0  \n\n[27481 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>text_without_stopwords</th>\n      <th>text_features</th>\n      <th>word_count</th>\n      <th>char_count</th>\n      <th>has_links</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id have responded if i were going</td>\n      <td>neutral</td>\n      <td>[id, have, responded, if, i, were, going]</td>\n      <td>id responded going</td>\n      <td>{'word_count': 7, 'char_count': 34, 'has_links...</td>\n      <td>7.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sooo sad i will miss you here in san diego</td>\n      <td>negative</td>\n      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n      <td>sooo sad miss san diego</td>\n      <td>{'word_count': 10, 'char_count': 43, 'has_link...</td>\n      <td>10.0</td>\n      <td>43.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me</td>\n      <td>negative</td>\n      <td>[my, boss, is, bullying, me]</td>\n      <td>boss bullying</td>\n      <td>{'word_count': 5, 'char_count': 22, 'has_links...</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview leave me alone</td>\n      <td>negative</td>\n      <td>[what, interview, leave, me, alone]</td>\n      <td>interview leave alone</td>\n      <td>{'word_count': 5, 'char_count': 30, 'has_links...</td>\n      <td>5.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sons of  why couldnt they put them on the rel...</td>\n      <td>negative</td>\n      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n      <td>sons couldnt put releases already bought</td>\n      <td>{'word_count': 13, 'char_count': 69, 'has_link...</td>\n      <td>13.0</td>\n      <td>69.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>ive wondered about rake to  the client has ma...</td>\n      <td>negative</td>\n      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n      <td>ive wondered rake client made clear net dont f...</td>\n      <td>{'word_count': 23, 'char_count': 115, 'has_lin...</td>\n      <td>21.0</td>\n      <td>109.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>yay good for both of you enjoy the break  you...</td>\n      <td>positive</td>\n      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n      <td>yay good enjoy break probably need hectic week...</td>\n      <td>{'word_count': 21, 'char_count': 109, 'has_lin...</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>but it was worth it</td>\n      <td>positive</td>\n      <td>[but, it, was, worth, it]</td>\n      <td>worth</td>\n      <td>{'word_count': 5, 'char_count': 22, 'has_links...</td>\n      <td>10.0</td>\n      <td>55.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>all this flirting going on  the atg smiles ...</td>\n      <td>neutral</td>\n      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n      <td>flirting going atg smiles yay hugs</td>\n      <td>{'word_count': 10, 'char_count': 55, 'has_link...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>314</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>125.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}